{"pages":[],"posts":[{"title":"LDA主题模型 | 玩家大型双标现场","text":"某项目数据的边角料利用~ 先放上来便于查看 不妥/踩线删~ 用 LDA算法 对《王者荣耀》&amp;《和平精英》春节档微博中关于“游戏崩了”的玩家舆情进行话题分析， 发现吃鸡的负面讨论内容 远少于农药。以下是话题聚类结果： 《王者荣耀》 【排位、队友】因游戏崩溃严重影响排位及开黑体验的负面情绪宣泄与辱骂： 如：王者荣耀服务器咦又崩了排位又输了； 王者荣耀服务器又炸了本伽罗正在排位疯狂收割好吗辣鸡； 王者荣耀服务器又崩了呜呜呜呜我打排位呢气死我了。 【进不去、更新、问题、以为】因崩溃进不去游戏错当更新的吐槽： 如：王者荣耀崩了我以为更新进不去还重启手机打脸； 第一把以为是我网的原因第二把开局全部卡飞服务器炸了啥时候能好呀心态扛不住呜呜呜王者荣耀王者荣耀服务器； 王者荣耀又更新了跪了一直进不去好不容易进去了也玩不了我还以为是我网卡了。 《和平精英》 【无聊、家里、打游戏、在家、出门】从游戏崩溃中得到“大家都很无聊”的认同与归属感： 如：看来大家是真的无聊，前天和平精英崩，今天会玩都崩了[跪了]追剧也停更太难了。 【进不去、排队、爆炸】吐槽游戏进不去（此外并没有其他体验方面的负面舆情）： 如：和平精英能不能行服务器爆炸了么； 和平精英服务器炸了死活进不去； 和平精英服务器炸了我操完全进不去； 吃鸡崩了。。。活久见 除了滴滴要排队以外，打游戏也要排队了； 和平精英服务器是崩了吗？开局还要排队。 【取消、聚会】吐槽在各类外出活动取消的情况下游戏崩溃： 如：电影取消了 话剧取消了 聚会取消了 泡温泉也取消了 想玩个游戏吧还崩了 #和平精英# 此外， 和平精英相关评论中最常见表情 Top10 分别为：[允悲]、[doge]、[泪]、[笑cry]、[二哈]、[跪了]、[微笑]、[费解]、[摊手] 和 [喵喵] ； 偏负面的有 [泪]（3/10）、[微笑]（7/10）、[费解]（8/10）和 [摊手]（9/10） 。占比 23.31%。 王者荣耀相关评论中最常见表情 Top10 分别为：[允悲]、[微笑]、[二哈]、[泪]、[拜拜]、[怒骂]、[费解]、[笑cry]、[怒] 和 [悲伤] ； 偏负面的有 [微笑]（2/10）、[泪]（4/10）、[拜拜]（5/10）、[怒骂]（6/10）、[费解]（7/10）、[怒]（9/10） 和 [悲伤]（10/10） 。占比 59.15%。 LDA的原理（是面试中被问到的问题！）","link":"/2020/03/24/LDA%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%8E%A9%E5%AE%B6%E5%A4%A7%E5%9E%8B%E5%8F%8C%E6%A0%87%E7%8E%B0%E5%9C%BA/"},{"title":"从《信任的进化》看重复博弈中的演化稳定战略与合作文化","text":"2019年秋季学期《游戏学导论》Report 4. 写在前面：关于《信任的进化》的沙盒模式我最喜欢《信任的进化》的地方在于它作为一款教育游戏，在一套固定的非零和博弈数值体系下，用沙盒模式提供给玩家基于实验而非单纯体验的理解方式。很多人在玩互动叙事类作品时都有意无意地像测试人员一样遍历更多选项，好奇某个决策会对后面的剧情造成什么影响。很少有玩家被推着走，然后接收游戏内容的灌输；而主动求证才是绝大多数玩家在低成本试错的游戏中最最没有顾虑的无意识行为。 但并不是所有游戏都能像《信任的进化》一样能够抽离出一套简约的数学规则，然后用于创建实验环境，告诉玩家“会变成怎样”。大部分行此道的游戏既要努力降低抽象玩法带给玩家的认知成本，又要找到一套沙盒运行的底层逻辑，亦颇考验策划的设计能力。 重复博弈使理性人走出囚徒困境自我偏好满足的最大化。在人与人之间一次性的短期博弈中，每个人都只顾考虑眼前利益，参与人的个体理性决定了他们都会选择不合作，以致帕累托最优无法实现双方都受损。 在重复博弈中每个参与人都能观察到博弈过去的历史，而其得到的最终报酬是各个阶段博弈支付的贴现值之和。正是由于博弈重复多次，参与人关心的不仅仅是现阶段的收益，还有未来的收益。正是这一点使得他们积极做出不同于一次博弈时的最优选择，并将该回合的选择建立在其他参与人行动历史的基础上。 博弈论放大了参与人的战略空间，我们试图将参与人在重复博弈中的诸多战略与《信任的进化》中的部分角色对应： 角色 策略 千年老油条 永远背叛（always defect）战略 万年小粉红 永远合作（always cooperate）战略 复读机 争锋相对（tit-for-tat）战略 黑帮老铁 触发战略/冷酷战略（trigger/grim strategy） 影响合作程度的战略尽管游戏中汉译来的“复读机”从字面意思上看与“争锋相对”战略大相径庭，但“争锋相对”作为成功率最高的一种战略，在某种程度上还是与“人类的本质是复读机”不谋而合。在《信任的进化》中我们看到笑到最后的只有复读机，而选择这种战略的人平均获得的报酬也是最高的。关于该策略，我们将在后文中从进化博弈理论的角度作更深层次的探讨。 冷酷战略（grim strategy）意味着对方一旦犯错，将永远不会再有合作的机会。在信息完全的情况下，这个战略反倒最容易导致合作的出现。因为参与者担心不合作就会受到惩罚，具体的惩罚体现在合作的终止，即本来有利可图的交易中断。 诚然对不合作行为的惩罚越严厉，合作的程度就越高。正因为害怕惩罚，所以不敢欺骗。这一结论只在没有不确定性的情况下才成立。但现实世界是不确定的，我们观察到的不合作行为也许并非对方故意而为。此时如果惩罚力度过大，就像冷酷战略，哪怕是对方不小心犯了错误，都会实施无限期的惩罚，并不一定有利于双方的长期合作。因此，为了维持合作，惩罚必须适度；不仅需要惩罚，有时也需要谅解和宽恕，即《信任的进化》中“复读机”的进阶版“复读鸭”。 囚徒困境与合作文化的演进在传统博弈（traditional game theory）理论范畴，一直维持着“理性人”的基本假设。在博弈中，每个参与人都有一个定义好的偏好和不受限制的推理能力。博弈的结构和理性是所有参与人的共同知识（common knowledge）。理性人可以理解和计算出所有参与人的互动策略。每个人选择的战略使自己的利益最大化。在这样一个框架下，只要知道博弈的基本结构——比如博弈的规则、信息结构等，理性人就可以通过理性计算出均衡战略。 但事实上，现实的情况可能不是这样。一个博弈的结构可能很复杂，如果得到均衡的结果需要复杂的推理能力，就像在象棋中虽然存在子博弈精炼均衡，但是很难计算出来。这也是很多社会学家对理性人假设持有怀疑的原因。比如决策问题，在我们的生活中的很多决策中决策人其实并没有经过仔细复杂的计算，而是简单地模仿别人，或者依靠过去的经验。 “复读机”们在做决策的时候，很大程度上是一个自发演进的过程，而不是一个精心设计的结果。传统的博弈论对这些现象和问题没有很好的解释，从生物学引入的演化博弈或可为这些问题提供一种新的理论角度。在生物学中的博弈并不是个体之间的博弈，而是基因的博弈。我们观察到的每个生物都是基因的载体。牛津大学教授道金斯在《自私的基因》里写到：“如果说我们每个人的倾向都是要最大化我们的效用的话，那么基因本身的倾向就是要最大化它的复制能力和生存能力。” 显而易见地在一个社会当中，幼稚合作的人（always cooperate，记作ALL-C）在遇到欺骗型（always defect，记作ALL-D）时，一定会比对方更糟糕，它们在一个演化博弈均衡当中是没有办法也没有可能生存的，势必被进化所淘汰。我们考虑n次重复博弈中争锋相对（TFT）和永远背叛（ALL-D）两种策略： 不妨假设人口中采用TFT战略的人比例是 ，对于这类人而言其一概率 遇到同类，得到收益 ，而以概率 遇到骗子，得到收益 ，故其预期收益为 。对于使用ALL-D战略的人，他只有一次机会行骗，因此预期收益为 。当前者大于后者时，采用TFT战略的人有生存优势，最后的均衡收敛到了全部采用TFT战略的人，即游戏中的“复读机”们，整个人口出现合作关系；反之就会收敛到全部采用ALL-D策略的全员恶人均衡。 由此我们画出最后社会达成合作的临界比例x和博弈重复次数n的关系图： 可以看到如果n=2，那么x大于1/3就足以导致合作均衡的出现；如果n=4，只要x&gt;0.1左右就足以导致合作均衡的出现。也就是说，在初始状态下，两个社会人口中都有接近90%的人不是合作类型的，但是如果一个社会里博弈会重复四次及四次以上，另外一个社会里只重复博弈两次，结果第一个社会就慢慢演变成一个合作型社会，而第二个社会中就会变成一个不合作的社会。 一言以蔽之，信任的长线积累对形成合作是必要的。且在重复博弈中，如果参与人有足够的耐心，合作可以作为精炼纳什均衡结果出现，而关键是有耐心的人更加在乎长远利益，从而愿意为长远利益放弃短期的机会主义行为。除了耐心，合作是否出现还受博弈重复的概率、行为的可观察性、对违约行为的惩罚等因素的影响，但在存在不确定性的情况下太严厉的惩罚也不利于合作，刑法上讲量刑适度，管理上说恩威并施都是出于此因。 结语本文结合《信任的进化》中的不同角色对重复博弈中的应对策略进行探讨，又从演化博弈的角度对社会是如何收敛到合作状态的过程作一数学推导上的证明。关于在人际交往中如何破解无限博弈与囚徒困境，无非信任先行、适度惩罚与长线关系中的声誉机制。 写到这里，《游戏学导论》的最后一次报告就收笔啦，尽管从第二次报告就开始朝着远超字数限制的方向一去不复返233。 可能比起徒然撰写问题的答案，我更想把作业当作一次契机，去接触到感兴趣的未知领域，并做到总结思考型的观点输出呈现。从二年级以后，几乎新闻学院的所有课都能给到我们这样的空间——我永远喜欢我的专业，也永远向往能允许这种自由存在的工作状态。","link":"/2019/12/15/%E4%BF%A1%E4%BB%BB%E7%9A%84%E8%BF%9B%E5%8C%96/"},{"title":"一个长长的实习总结","text":"眷恋余热.","link":"/2020/09/21/%E4%B8%80%E4%B8%AA%E9%95%BF%E9%95%BF%E7%9A%84%E5%AE%9E%E4%B9%A0%E6%80%BB%E7%BB%93/"},{"title":"1118-1124 寻章摘句","text":"这周看的三本书w 《数据的真相：如何在数据时代做出明智决策》+《游戏情感设计：如何触动玩家的心灵》+《算法霸权：数学杀伤性武器的威胁》 数据的真相：如何在数据时代做出明智决策 你必须时常问自己，是否能够准确地将研究发现从样本推广到数据总体？这种推广的可能性称作外延有效性，即把从样品中得出的结论加以推广，从而得出对整个数据总体有意义的结论。 如果缺失的地基位于错误的位置——或缺失太多地基，那整座房子将会倒塌。 有些故事之所以能够成为新闻，只因其报道的是离群值。老生常谈和那些非比寻常的事相比，常常会显得没有那么激动人心。 在一个良好的统计模型中，应该能够任意排除一个数据，统计结果不会因之发生显著变化。 关联性和因果性不同，这其实是人们解读数据时最常见的错误之一。 遗漏变量是造成关联性和因果性不同的主要原因。 只需牢记一句话，尽管你所运用的是能够掌握的最佳数据，但想要证明因果关系依然是一场硬仗。 虚假关联很有用，因为可以凸显出遗漏变量的存在，并描绘出将关联等同于因果会导致的潜在危险。 在你日常生活中看待互为关联的事物时应牢记于心。自我提问：两者的关联性纯粹只是巧合？还是由遗漏变量在起作用？ 统计学并非总是完美的，但它提供了一个维度，让人可以用科学的方式评估数据。 弗里德曼《最佳工作场所：创造一个非凡的工作场所所需要的艺术与科学》：“我们的大脑通过进化，变得擅于寻找秩序、预测事情发展。我们无法控制这个过程——我们就会处处寻找联系，即使联系并不存在” 实证性偏见几乎影响着你对待数据的方方面面——从抽样到观察到预测——因此在解读数据的时候，你必须时时留心。在研究关联性和因果性的时候，实证性偏见是有些人忽略遗漏变量的一大原因 因为他们凭借先入为主的观念，而且基于真实的数据，把两件事时间的关联性当成了因果性。 置信区间和置信水平在科学论文与科学研究中应用广泛，而在针对科学论文和研究的媒体报道中所见甚少。这存在问题，因为一旦离开了置信区间和置信水平，就无法知道事情的全部真相。 显著性差异并不能支配一切。哪怕已经的处理显著性差异，依然需要留心我们在本书中提到的其他因素（遗漏变量、离群值等），除此之外还有其他的一系列偏差（证实偏差、选择偏差等） 下面有5件你可以立即着手去做的事，以此了解自己所看到的数据是否真的都有用。 确定所看到的结果是否随机出现要了解，许多研究发现其实是基于或然性的。 很多情况下我们会得出可以确信的结论，但要记住，我们只是在衡量或然性而已。 要知道，你在新闻标题中看到的数据常常是范围中的一个值。 哪怕得出了显著性差异的效应，也要看一下效应量。思考数据对你生活产生的影响。 不要赋予任何数据超出其自身的意义。他看似很有说服力，但未必能准确地呈现出事情的全貌。 伊利诺伊大学教授、商学院商业与公共政策中心主任杰弗里布朗，他说：“正确看待预测的方式是将其看做一种缩小出现不同结果可能性的手段”，即缩小‘任何事情都可能会发生’与‘这就是可能会发生的结果’二者间范围。实证性偏见（confirmation bias）用巩固自己预期的方式解释数据的倾向外延有效性（external validity）把从样品中得出的结论加以推广，从而得出对整个数据总体有意义的结论。 游戏情感设计：如何触动玩家的心灵第一章 一系列有趣的选择：情感设计的构建模块 我们对公益游戏（为公益事业而设计的游戏）赋予了过高的期望——和很多非盈利组织、健康机构及社会性企业一样，我们没有意识到糟糕的游戏设计连最基本的效果都达不到。为了实现学习、训练或者健康等设计目的，我们很有可能做出糟糕的、无聊的、=没有吸引力的游戏。 游戏和其他媒介最基本的区别是：它们为玩家们提供了通过自己的努力来影响结果的机会。能够影响结果的操作——有趣的选择——给了游戏设计师们创造一系列新的情感体验的可能性。归根结底，这些可能性之所以存在是因为在日常生活中，我们的情感是和我们的目标、选择及选择的结果密切相关的，在游戏中也一样。当面临很多选择时，人们会经历一个快速和自动化的评估过程，来评估每件事情对他们的目标和计划会产生怎么样的影响。在这个评估过程中，情感会被激发，以引导做出快速、适当的行为。 一些观影者或读者在经过了一段时间后确实会对角色产生强烈的情感依附，这些现象会称为拟社会现象。 （游戏）它允许我们去经历另一种人生，同时也组成了我们自己人生经历的一部分。 经过长时间的游戏，玩家们会把自己的动机与本能、认知、社交和幻想四个层面的可能性渐渐融入到游戏角色上，基于观察、行为和体验，获得一种身份上的认同。和其他媒体中的角色相比，玩家会更深地投入到游戏角色中，因为游戏角色能在多重心理层面上提供行为的可能性。 《模拟人生》系列游戏顽皮的人物角色设计让游戏变得格外吸引人。拿些没有异议的喃喃碎语，简化的卡通形象和对话，其实会比高度细化的精致的对白、界面和美术风格留给玩家更多想象的空间。一个抽象的、程序化的角色表现形式更容易让观看者将自己投射到角色身上，而不会因为角色身上特殊的人物品质和怪癖而分心。 游戏设计师们使用这些方法不只是娱乐，同时也为了唤起更深的意识觉醒， 与他人相处的责任感与复杂性。 游戏角色和NPC们也允许并鼓励我们和他们建立一种深刻而有意义的虚拟关系 第二章 社交游戏：多人玩家情感的设计 研究人员试着通过问卷调查进和生理指标的测量（皮肤电反应 GSR 和肌电图肌肉活动测量法 EMG）来鉴别每种情况下玩家反映的不同。 问卷调研：测量玩家的主观认知和偏好生理指标测量：也许会和玩家的主观报告有所区别 游戏设计师们在社交游戏中用来唤起玩家丰富情感反馈的三种构建模块：协调行动、角色扮演和社交场合。 游戏设计师们设置特定的社交场景，目的是触发某些特定的行为和冲动，从而创造出他们希望玩家们能共同体验到的情感和社交反馈。因为他揭示了一种强大的玩家合作文化，即使面对的是新的规则、竞争元素和奖励系统。 第三章 游戏中的肢体动作：运用动作设计来创造情感和联系 游戏设计师们运用运动来塑造情感和社会联系的三种方法——设置身体挑战来引发情感反应，运用运动来促进有趣的社交动态，以及使用身体作为一种工具来把玩家幻想的身份带到身份中。 设计师们意识到删除玩家视频，用一个自信、流畅的游戏角色代替屏幕上的玩家是更好的方案。 那些把玩家们的身体调整到新的、意想不到的身体结构的运动能够触发强烈的社交和情感体验。 通过运动来唤起情感并驱动有趣的社交关系和体验的效率就越高。本章提到的独立游戏使用了声音、触觉反馈和人力支持（类似MC主持人这样的角色）来打破玩家对屏幕的紧密的视觉依赖。 我们已经看到了掌握一项新的身体机能时所产生的强大情感力量，也看到了与其他人一起运动时候所产生的社交与情感力量。基于身体设计游戏的第三个方面，就是让玩家利用自己的身体来培养假想身份，使情绪在一定范围内转变成为可能。 电子游戏设计师们现在可以把玩家身体本身当做一种媒介来塑造情感和建立社交连接。 第四章 消除隔阂，创造亲密感和联系 设计师使用的三个策略：数字道具的分享与交流，夏令营式的游戏环境的培养，以及围绕游戏建立业余玩家与专业玩家的社区。 魔法圈是在20世纪30年代由荷兰历史学家和文化理论家 Johan Huizinga 创造的一个术语——一个安全、有界的环境，玩家在其中可以将奇幻与真实结合在一起，并因此使得更自由更自如的社会联系和情感表达更容易发生。 玩家和学者已经撰写了许多关于长期在虚拟世界中进行游戏而形成的强大社交和情感纽带的文章。但很少有人探索另一种网络游戏中的社区建设能力，那就是异步大规模游戏（玩家在不同时间参与同一种游戏） 算法霸权：数学杀伤性武器的威胁第一章 盲点炸弹：不透明、规模化和毁灭性 棒球模型基本上是一种健康模型。这种模型信息透明，不断更新。棒球模型仰赖比赛进行过程中积累的真实数据，而不是替代性的间接变量。家庭饮食模型，良性模型，假设清晰。但很难规模化。再犯模型绝非个例。不透明、隐形成了这些模型的规则，清晰、透明的模型倒成了例外。即使这些模型是良性模型，不透明还是给人一种不公平的感觉。 对一部分人不公平的关键原因是模型造成的恶性循环。它会自行创建一种使假设合理化的环境。而模型则在此恶性循环的过程中变得越来越不公平。 数字杀伤性武器共有三个特征：不透明、规模化、毁灭性。这些数学杀伤性武器关闭了亿万人的忌讳之门，通常只是因为一个微不足道的理由，而且不予他们上诉的机会。因此它们仍然是不公平的模型。 第二章 操纵与恐吓：弹震症患者的醒悟 我越来越担心技术模型与现实世界中的有血有肉的个体的相互分离的趋势，以及这种分离带来的道德影响。事实上，我在数据、科学领域看到了我在金融领域见到过的同样的模式：一种盲目的安全感导致的不完善模型的广泛应用，模型对于评估效果的自我定义，以及加速恶化的反馈循环。而与此同时，模型的反对者被认为是落后的科技恐慌分子。 第三章 恶意循环：排名模型的特权与焦虑 其中大量的评估因素仅仅来自直觉，模型确立的过程并不眼睛，统计分析也缺少根据。在大学排名这个案例中，模型建立的一句仅仅是人们凭空想象什么是对教育而言最重要的因素。然后这些人便去寻找可以测量的相关变量，最后随意地在公式中赋予每个变量一定的权重。 在大部分领域中，模型确立的过程通常还是比较严谨的。如农业学科的研究者会比较投入（土壤、阳光和化肥）和产出（收获后，具有特定特征的农作物的产量。）然后他们就可以按照他们的目标，比如一定的成本、口感或者应将价值等进行下一步的实验和优化。但这并不是说农学家就不可能建立数学杀伤性武器。他们也曾经建立过数学杀伤性武器（尤其是当他们没有考虑到杀虫剂长期而广泛的影响时）。但是，因为他们的模型在大多数情况下关注的是一个明确的结果，所以我们依然认为这是一个相对理想的科学实验过程。 当你基于替代变量建立模型时，钻模型的漏洞会变得容易很多。这是因为替代变量比起其所代表的的复杂事实更容易操控。 每一个排名模型都有漏洞可钻，而一旦被钻了空子，模型就会产生新一轮恶心循环以及大量意料之外的有害后果。 第四章 数据经济：掠夺式广告的赢家 互联网基于我们的网上行为所透露出来的内在偏好和萱蕚模式，把我们放在数百种模型中进行排名、分类以及评分。这为合法的广告营销奠定的了强大的基础，但同时也助长了掠夺式广告的兴趣，后者指精确找出有迫切需求的群体，并向他们兜售虚假承诺的广告。掠夺式广告以寻找不平等并大肆利用不平等为己任，其结果是进一步巩固了现有的社会分层。整个社会最大的分水岭就出现在这个系统的赢家（比如风险投资人）和赢家所建立的模型的掠夺目标之间。 在人民既有迫切需求又对具体信息很无知的任何地方，你都能看到掠夺式广告。它们大规模聚集于社会中最绝望的那群人。在教育方面，它们承诺通向成功的道路，但这条路的重点往往是贫穷的深渊。受害者们几乎无从了解他们是如何被选中的，或者广告商是如何能够对他们有那么详尽了解的。 第五章 效率权衡与逻辑漏洞：大数据时代的正义第六章 筛选：颅相学的偏见强化更糟糕的是，一旦模型经过了技术专家的校准投入使用，此后模型收到的可用于修正的反馈数据就变的极少。 第七章 反馈：辛普森悖论的噪声 一如许多其他的数学杀伤性武器，问题的根源在于模型创建者选择了什么目标。这些模型追求的是效率和盈利的最大化，而不是正义或“团队”的福祉。 大量的数学杀伤性武器，只不过是在打造它们自己所定义行家本应在试图弄清楚一的现实。 辛普森悖论：在某个条件下，两组数据在讨论时都满足了某种性质，可是一旦合并考虑，就可能导致相同的结论。 第八章 替代变量和间接损害：信用数据的陷阱 所有这些数据点都是替代变量。这位银位客户的支付能力的过程审中冷静地研究这些数据（一些传统的银行家一定会如此）。但是与之相反，这位银行家草率地把这些数据与种族、宗教和家庭关系联系在一起。此举避免了查借款人的个人情况的麻烦，而把借款人归入到一个群体之中，今天的统计学家称之为“池”。然后，这位银行家会决定“像你这样的那类人”能不能被信任。 随着电子评分甚嚣尘上，我们被一些秘密算法归类分组，其中有些算法仰赖的还是错误百出的个人档案。我们不是被当做个体，而是被当做某个群体的一员，被迫戴上了某顶帽子。 第九章 “一般人”共识：沉溺与歧视 模型在我们看不到的地方仍然把我们归类为各种各样的群体，以各种行为模式为指标。不管最终的分析正确与否，这种不透明性都会导致欺诈。 这些自动化程序将日益决定着我们会如何被其他系统对待，后者将决定我们看到的广告、为我们设定商品的价格。这些系统运作高校，表面上看只是给出了随机的建议，同时完全不给出任何解释。没有人能够理解这些系统的内在逻辑或者解释我们收到的这些信息的原因。如果我们不夺回一定程度的控制权，这些未来的数学杀伤性武器将会成为隐藏在人类社会幕后的控制者。它们将以它们的方式对待我们，而我们却对此毫不知情。 第十章 正面的力量： 微目标的出发点 然而超市模型与选民模型之间有一个关键的不同。在超市模型中，所有可用数据都与购物密切相关。他们通过研究人们的购物模式，来预测（和影响）人们的购物行为。但在政治选取方面，密切相关的可用数据则少之又少。要建立这个模型，数据团队需要找到替代变量，可这需要建立在深入调查的基础上。 这种通过挖掘数据建立个人档案预测个人行为的为目标锁定技术经不断发展，已完全符合我们所说的数学杀伤性武器的所有特征。这种技术影响范围广，不透明，且不负责任。在该技术的掩护下，政客们得以更顺利地在不同人面前展示自己。 结论我们如何规范这些逐渐渗透继而操纵着我们整个生活的数学模型呢？我建议从建模者自己开始做起。数据科学家应该像医生一样遵守希波克拉底誓言，尽可能放置或避免对模型可能的误用和误解。2008年经济危机爆发之后，伊曼纽尔德曼和保罗威尔莫特两名金融工程师起草了这个誓言。内容如下： 我将牢记我并未创造世界，也不会让世界来满足我的方程式； 虽然我将大胆使用模型来估算价值，但不会过分倚重这一数学分析； 我将永远不会为了追求模型的间接而牺牲现实的复杂，除非我能够对我这样做的原因给出一个合理的解释； 我也不会向使用我所创建的模型的人们夸大模型的精确性。 相反，我将明确说明模型中的假设条件与模型忽略的因素；我明白我的工作可能会对社会和经济造成巨大影响，其中的许多影响将超出我的认知范畴。 这是我们的数学杀伤性武器消除行动的一个很好的哲学基础。但坚定的价值观和自我约束只对谨慎的人有效。更重要的是，这一改变后的希波克拉底誓言忽略了数据科学家在寻求他们的牢门所需求的具体答案时的实际压力。要想消灭数学杀伤性武器，我们不仅仅要在数据行业确立最佳反例，还要推行相关的法律条例，要想实现这一目标，我们必须重新评估模型的成功标准。 针对数学杀伤性武器建立的监管系统必须衡量这些潜在成本，同时还要体现更多的非数值价值。","link":"/2019/11/24/1118-1124%20%E5%AF%BB%E7%AB%A0%E6%91%98%E5%8F%A5/"},{"title":"Pre讲稿整理 | 咪蒙爆款文套路大赏","text":"2019年秋季学期《数据挖掘》结课展示讲稿. 大家好，我是传播1701班的卢丹，今天由我来代表我们组做这样一个数据挖掘课程的最终展示。我们组的选题是咪蒙爆款文套路大赏，分析对象是咪蒙公众号从2015年9月15日到2019年1月29日以来的所有更新内容。接下来我将从这四个方面：问题的提出与分析、研究过程与技术细节、研究发现、结论与讨论向大家做一展示。 首先来看我们的分析数据集。大家都知道现在虽然是大数据时代，但要拿到好的数据来进行分析其实并不是一件容易的事情。很多网站都有非常厉害的反爬机制，所以我们这次数据先行，先从这样一些和数据挖掘有关的网站找到感兴趣并有一定分析价值的数据。我们当时定了两个选题，分别是这里的咪蒙文章风格和豆瓣书籍数据。我们对这里的研究框架和意义做了分别做了一定的先导分析。那最终结合团队成员的兴趣倾向和老师的建议选了咪蒙的这样一个选题。 我们的数据包括了咪蒙从2016年9月15日到2019年1月29日的1072篇内容，除去原文链接这些没什么价值的属性，在分析的时候能用到的字段有阅读量、点赞量、发文时间、作者、标题及文本全文这些字段。 在确定好选题并且拿到数据后，我们在知网以“咪蒙”为关键词进行搜索，发现相关文献约一百来篇，从17年开始发表数量一直上升，到今年咪蒙被封号了反倒最多。 那学者们都在研究什么主题呢？这里是输出的文献主题分布，其实在今年以前，大家更多关注的还是咪蒙这样一个头部情感类公众号的写作和传播策略；那在今年之后，越来越多的人就开始对咪蒙现象进行批判反思。 再回到我们自己的分析上，综合过往的相关研究和数据集详情，我们提出了这里的三个问题。 这里是我们的研究过程与方法，针对每个问题我们都有从特定预设维度进行的统计学描述；除此之外还有共现矩阵、关键词抽取、LDA主题聚类、训练模型然后进行的文本生成。那详细过程在这部分就不详述了，我们来看具体的研究结果。 公众号运营数据首先是公众号运营数据。 从更新频率来说，我们发现咪蒙在16、17、18三个整年里，平均64.1%的天数都在更新，大家可以在右边的更新热度图中看到这个咪蒙的更新频率确实非常之勤快，甚至在18年的时候有将近80%的天数都在更新。 我们发现其公众号最长连更天数有32天，断更的间隔则为28天，而且所谓的断更还不是她自己不想写，而是因为禁言导致的被迫不能写。 大多数情况下它的这个推送量是一天一到两篇，但是我们发现还存在少部分一天发3篇、4篇、甚至5篇的时候。我们比对了一下时间线，当时应该是咪蒙举办“新媒体创作大赛”的时候，而且这天的阅读量都是10w+，可见咪蒙团队的赛事运营能力也是很OK的。 然后关于单篇的发文时间，不出意外地可以看到咪蒙发文的时间主要集中在晚上十点以后，而在对其他几个头部情感类公众号最近一个月的发文时段进行调查后，我们发现情感类公众号都倾向于晚上更新，来唤起天黑后大脑边缘活动增强而导致的一些情绪。 这里因为咪蒙绝大部分内容的阅读量都在10万+，所以我们在拉热度趋势图的时候选择点赞量进行指标分析，总的来看咪蒙的成绩是比较稳的，点赞大部分都落在3w以下的区间，而且集中在1w到2w里。 那这里我们也同样选择了两个同类竞品公众号，从这里的图可以非常直观地看到，在大家头条平均阅读量都是10w+的情况下，咪蒙的平均点赞量远超过其他两个公众号几倍之多。点赞其实更像是受众在触媒后的这样一个采纳行为，说明咪蒙公众号的影响力要显著高于两个其他同类头部公众号。 公众号署名作者然后是第二个问题，公众号的署名作者。 我们发现在1072篇内容中，除了46次图片分享外的文章也有单人作者和多人合作署名。接下来我们将重点关注这两部分。 在一千多篇文章里，咪蒙的撰写量有791篇。而且点赞数最多的十篇文章，都是7w点赞起步，咪蒙一个人占了七篇。作为山东大学文学院的硕士，她的个人撰稿能力真的非常能打。 然后我们计算了一下作者的单篇平均点赞量，这时候咪蒙的排名就靠后了，因为她的数量特别多确实算平均的话有点分散。有意思的是，我们发现这样计算下来的单篇平均点赞量前十里的作者除了“大志”这一位之外，其余都是凭孤篇排到前三。排名前三的三位同学还是之前所说在咪蒙办的比赛中拔得头筹的选手。可见咪蒙除了赛事运营能力外，造星能力或者说个人品牌运作能力也是非常强的。 这里我们画出了合作作者的共现关系图，两两作者间的线越粗，说明他们合作的频次越高。那这个图的中心显而易见就是咪蒙了，有意思的是我们从点赞量切入去研究，就发现大部分作者在跟咪蒙老师合作后都获得了优于自己平均点赞的好成绩。之前我们说咪蒙的撰稿能力、运作能力强，那到这里要夸一夸她带新人的能力了。 公众号文章内容我们现在来看最后一个问题，公众号的文本内容。 我们首先针对标题字数进行了统计，结果如图所示。咪蒙公众号的标题多在10到20字的区间内，16个字长度的标题最常见。正文字数最常见的情况在2500-3000左右。以成年人的正常阅读速度的上下限来估算，一篇上述篇幅的文章，全文阅读完毕大概在三到八分钟。 这里对咪蒙文章标题的分类引自新榜公众号在17年2月28日的一篇推送，那我们对于标题的研究切入点还是标点符号。咪蒙的标题中使用标点符号是一件非常常见的事情。在对公众号的所使用的标点符号进行统计后我们发现，最长出现的标点符号分别是逗号、感叹号和问号。 美国社会学家米德提出的符号互动论认为符号的意义在于对现实社会的建构。问号有质疑、反问、设置悬念的作用，在标题中就能激发受众的探究欲；省略号同样也是借营造的丰富想象空间来吸引受众点进来。从用的更频繁的感叹号，大家就能看出来咪蒙的情绪表露诱导有多强烈了。 关于标题的研究我们有一个文本生成的小彩蛋暂时放在后面，下面我们来看正文。 这里我们在没有设置停用词的情况下画出了标题和正文的高频词词云图。之所以没有去掉停用词，是因为我们发现咪蒙的行文充斥着大量的常用停用词，如自己、我们、一个，如果把这些去掉，反倒更不利于观察咪蒙的文章风格。 虽然这里的词云说服力也蛮弱的，因为它是将一千多篇文章大杂烩后进行的统计，信息掺杂在一起也看不出来什么。于是我们又对单篇文章进行权重Top10的这样一个关键词抽取，按照文章发表的时间顺序做成了视频。 （放视频） 这个视频一共有三十来分钟，就从文章里抽取了十个关键词。但要命的是，我们发现每天的关键词基本没有重合的，每天的这个轴都是从零开始往出来走。 这其实是因为我们之前的文本预处理不够，我们简单粗暴地对每篇文章的进行分词，这样分下来就是一个高维稀疏的矩阵，每个维度都是文本的一个词。所以我们接下来做的就是文本的聚类和文本特征的降维。 这里我们调用百度自然语言处理的AI进行文本分类，它的请求参数和返回参数分别如右边所示。比如15年11月10日的这篇文章，就可以返回时尚这一个一级分类维度和化妆、美容这两个二级维度。 于是我们对咪蒙公众号文章主题的分别就一级维度和二级维度各类别的占比进行了统计。可以看到，一级维度里最常见的内容主题是社会、情感、母婴育儿和娱乐；那再细分一下，二级维度里最常见的内容主题则是两性、恋爱、婚姻和大学。 真的是非常关注女性粉丝的精准定位和贴近用户群体的观点输出。 基于先前这些对文本主题、标题规律这些的研究，我们在这里提出两点假设： 其一，咪蒙系的文章中存在着大量的身份立场纠葛 其二，咪蒙系的文章中充斥着大量激烈的情绪化表达 接下来我们分别采用关系矩阵共现和情感极性比率计算的方法来尝试对这两个假设做某种意义上的验证。 这里本来应该做全关系抽取，但因为技术太菜所以我们退而求其次画出了朋友关系的共现网络图，两个身份角色之间的边越粗，表示它们同时出现在一篇文章中共现的情况就越常见；右边的弦图对关系的比例程度做了一个更清晰的呈现。那我们从中可以看到，像前男友、前女友、男朋友、女朋友这些恋爱中的两性关系，在咪蒙的文章中共现频率是十分之高的。 接下来关于情绪化表达，我们这里将一篇文章拆成单句放在列表中，然后计算单句极性，统计单篇文章中情感极性小于0.2或大于0.8的句子所占比例。从左边的散点图中可以看到，这一千多篇文章基本都是维持到30%-40%的水平，而且都比较集中，咪蒙的输出还是稳，这说明咪蒙的绝大部分文章中有30%到40%的句子都是情感很强烈的。我们还用其他语料做了测试，发现新闻报道中这类句子的含率不到10%，而豆瓣电影评论中的占比六十起步百分百封顶。 在最后一部分总结之前，我还想用两分钟时间向大家展示我们组做的咪蒙式标题文本生成，我们这里用到了基于循环神经网络写的这样一个自然语言处理库，所谓循环神经网络，它相比BP算法或卷积神经网络，它不仅考虑前一时刻的输入，还考虑这个时刻之前的记忆。右下角是我们设置的一些超参，因为跑一整遍模型时间很长，我在这里就只展示录屏，我们跑了20轮，最后梯度从7.2373下降到0.9371，虽然这个数字还很不好看，但从训练的结果来看已经开始说人话了。 （放视频） 这个就是我们训练的文本生成模型。 总结与讨论最后这里是我们这整个研究过程的回顾，运营数据、署名作者、文本内容三个大的维度下的一些研究结论，我随便念几个。 我们开篇标题是咪蒙爆款文套路大赏，基于上述研究我们认为：赋予争议性的社会热点选题、包含视觉刺激与情绪挑逗的标题和刻板符号化的对立冲突就是咪蒙文一贯的套路。 最后还有三点对我们这整个研究过程的不足反思。因为咪蒙封号是在今年一月，我们确实搞不到当时公众号下的评论，所以我们这次没有涉及对传播效果的研究；那相比前面的一些组来说，我们的研究框架更倾向于探究“事实是什么”的问题框架，而非“什么导致了这样？”、有理论依托的框架。最后一点就是很多技术细节的原理对我们来说都是黑箱，还存在非常多对模型也好、思路也罢没有想清楚的地方，请大家多多指正~~ 我们组的展示就到这里结束啦，我们组的成员是陈祺汇、陈雨嫣、我、钟晨欣和朱淑婷，非常感谢全组成员这半个月的付出，再次谢谢大家。","link":"/2019/12/22/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%BB%93%E8%AF%BE%E5%B1%95%E7%A4%BA%E8%AE%B2%E7%A8%BF/"},{"title":"机器学习大乱斗 | 游戏评论的情感分类","text":"关于情感分类的机器学习. 新手入门向. 前言5000条 TapTap 评论情感标注数据集来自https://www.kesci.com/home/dataset/5d2d3745688d36002c5db766。 笔者以前并未接触过机器学习项目，因此本篇博客旨在扫描相关知识盲区(⁄ ⁄•⁄ω⁄•⁄ ⁄)。 模型的选取与性能测试并非所有模型都适合文本分类，scikit-learn的这张图可以算是经典机器学习模型的选择指南。这张图指向了朴素贝叶斯模型，而在N多个模型中确实也是贝叶斯表现最好。 之所以要分出训练集和测试集，是因为如果将训练数据集直接作为评估数据集，会过拟合而不具备泛化能力。 可以手动切分数据集： 12345678910111213VALIDATION_SPLIT = 0.16 # 验证集比例TEST_SPLIT = 0.2 # 测试集比例p1 = int(len(data) * (1 - VALIDATION_SPLIT - TEST_SPLIT))p2 = int(len(data) * (1 - TEST_SPLIT))x_train = data[:p1]y_train = labels[:p1]x_val = data[p1:p2]y_val = labels[p1:p2]x_test = data[p2:]y_test = labels[p2:]print('train docs: ' + str(len(x_train)))print('val docs: ' + str(len(x_val)))print('test docs: ' + str(len(x_test))) 也可以用 scikit-learn 中的 train_test_split 来分离数据 1X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2) K折交叉验证分离 K折交叉验证是将原始数据分成K组（一般是均分），将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，这样会得到K个模型，再用这K个模型最终的验证集的分类准确率的平均数，作为此K折交叉验证下分类器的性能指标。K一般大于等于2，实际操作时一般从3开始取值，只有在原始数据集和数据量小的时候才会尝试取2。K折交叉验证可以有效地避免过拟合及欠拟合状态的发生。 可以用 scikit-learn 中的 cross_val_score 做交叉验证和打分 1scores = cross_val_score(model, X_train, y_train, cv=5,scoring='accuracy') 弃一交叉验证分离 如果原始数据有N个样本，那么弃一交叉验证就是N-1个交叉验证，即每个样本单独作为验证集，其余的N-1个样本作为训练集，所以弃一交叉验证会得到N个模型，用这N个模型最终的验证集的分类准确率的平均数作为此次弃一交叉验证分类器的性能指标。 弃一交叉验证分离每一回合中几乎所有的样本皆用于训练模型，因此最接近原始样本的分布，这样评估所得的结果比较可靠。实验过程中没有随机因素会影响实验数据，确保实验过程是可以被复制的。 但弃一交叉验证的缺点是计算成本高，因为需要建立的模型数量与原始数据样本数量相同，当原始数据样本数量相当多时，弃一交叉验证在实际运行上便有困难，需要花费大量的时间来完成算法的运算与评估，除非每次训练分类器得到模型的速度很快，或者可以用并行化计算减少计算所需的时间。 123from sklearn.model_selection import LeaveOneOutloocv = LeaveOneOut()scores = cross_val_score(X, y, cv=loocv) 算法评估矩阵1234scoring = 'accuracy' //准确度scoring = 'neg_log_loss' //对数损失函数scoring = 'roc_auc' //AUC图scores = cross_val_score(model, X_train, y_train, cv=5,scoring='accuracy') 分类准确度 分类准确度就是算法自动分类正确的样本数除以所有的样本数得出的结果。通常，准确度越高，分类器越好。这是分类算法中最常见，也最易被误用的评估参数。准确度确实是一个很好、很直观的评价指标，但是有时候准确度高并不代表算法就一定好。（数据分布不均匀） 对数损失函数 在逻辑回归的推导中，它假设样本服从伯努利分布（0~1分布），然后求得满足该分布的似然函数，再取对数、求极值等。而逻辑回归并没有求似然函数的极值，而是把极大化当作一种思想，进而推导出它的经验风险函数为：最小化负的似然函数 $max F(y, f(x))→min-F(y,f(x))$。 从损失函数的视角来看，它就成了对数（Log）损失函数了。对数损失函数越小，模型就越好，而且使损失函数尽量是一个凸函数，便于收敛计算。 AUC图 实际结果-1 实际结果-0 预测结果-1 True Positive（TP） Flase Positive（FP） 预测结果-0 Flase Negative（FN） True Negative（TN） 定义敏感性指标为$$sensitivity=\\frac{TP}{TP+FN}$$定义负正类率为$$FPR=\\frac{FP}{FP+TN}$$定义特异性指标为$$Specificity=\\frac{TN}{FP+TN}=1-FPR$$ ROC是受试者工作特征曲线（Receiver OperatingCharacteristic Curve）的简写，又称为感受性曲线（Sensitivity Curve）。得此名的原因在于曲线上各点反映相同的感受性，它们都是对同一信号刺激的反应，只不过是在几种不同的判定标准下所得的结果而已。 ROC是反映敏感性和特异性连续变量的综合指标，用构图法揭示敏感性和特异性的相互关系，通过将连续变量设定出多个不同的临界值计算出一系列敏感性和特异性，再以敏感性为纵坐标、（1-特异性）为横坐标绘制成曲线。 AUC是ROC曲线下的面积（AreaUnder ROC Curve）的简称，AUC的值就是处于ROC Curve下方的那部分面积的大小。通常，AUC的值介于0.5到1.0之间，AUC的值越大，诊断准确性越高。在ROC曲线上，靠近坐标图左上方的点为敏感性和特异性均较高的临界值。 混淆矩阵 混淆矩阵（Cnfusion Matrix）主要用于比较分类结果和实际测得值，可以把分类结果的精度显示在一个混淆矩阵里面。混淆矩阵是可视化工具，特别适用于监督学习，在无监督学习时一般叫作匹配矩阵。混淆矩阵的每列代表预测类别，每列的总数表示预测为该类别的数据的数目；每行代表数据的真实归属类别，每行的数据总数表示该类别的数据的数目。 123456789model = LogisticRegression()model.fit(X_train, Y_traing)predicted = model.predict(X_test)matrix = confusion_matrix(Y_test, predicted)classes = ['0', '1']dataframe = pd.DataFframe(data=matrix, index=classes, columns=classes)print(dataframe) 分类报告 在scikit-learn中提供了一个非常方便的工具，可以给出对分类问题的评估报告，Classification_report()方法能够给出精确率（precision）、召回率（recall）、F1值（F1-score）和样本数目（support）。在这里简单地介绍一下三个指标数据：精确率、召回率、F1值。 精确率 $p=\\frac{TP}{TP+FP}$ 召回率 $p=\\frac{TP}{TP+FN}$ F1 精确率和召回率的调和均值 12from sklearn.metrics import classification_reportreport = classification_report(Y_test, predicted) 机器学习算法的比较1234567891011121314151617181920212223models = {}models['Logistic'] = LogisticRegression(solver='liblinear')models['RandomForest'] = RandomForestClassifier()models['SVM'] = SVC(kernel='linear')models['KNN'] = KNeighborsClassifier()models['CART'] = DecisionTreeClassifier()models['NB'] = MultinomialNB()results = []for name in models: pipe = make_pipeline(tfid_vect, models[name]) result = cross_val_score(pipe, X_train.cutted_comment, y_train, cv=10, scoring='accuracy') results.append(result) pipe.fit(X_train.cutted_comment, y_train) y_pred = pipe.predict(X_test.cutted_comment) msg = '%s: %.3f (%.3f)' % (name,result.mean(),result.std()) print(msg)fig = pyplot.figure()fig.suptitle('Algorithm Comparison')ax = fig.add_subplot(111)pyplot.boxplot(results)ax.set_xticklabels(models.keys())pyplot.show() 执行结果给出了每种算法的平均准确度与标准方差： Logistic: 0.812 (0.015) RandomForest: 0.729 (0.018) SVM: 0.802 (0.014) KNN: 0.683 (0.015) CART: 0.677 (0.025) NB: 0.808 (0.016) 也可以通过箱线图展示算法的准确度，以及10折交叉验证中每次验证结果的分布状况。","link":"/2020/02/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E4%B9%B1%E6%96%97_%E6%B8%B8%E6%88%8F%E8%AF%84%E8%AE%BA%E7%9A%84%E4%BA%8C%E5%85%83%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"},{"title":"【研究素养提升指北】用问题拉动研究的正确打开方式 Vol.1","text":"今天和优秀用研经理交流了吗.jpg（1/2） 写在前面不是很想把这篇总结写成深访小结。刚好最近在做项目的时候暴露出一些令人烦躁的问题，而且十分迟钝地仍然困于其中不得解；尽管没有事先准备提纲（下次一定，狗头.jpg），和前辈交流的时候还是下意识地抛出了一些相关的问题；所以趁着 sloan 的几句提点还在颅内停留，干脆揉碎了写一写关于这次项目的思考好啦。 “面对一大波数据，觉得有很多可以分析的地方；但罗列到报告上又觉得意义不大，或者说很难判断出什么是值得写的结论”。这是当时被问及近况时下意识最先抛出的困惑，sloan 给出的问答是“一定要想清楚你的报告需要回答哪些问题，你可以给出哪些假设”。 说自己以前完全没有问题意识是假的，毕竟这段时间写报告就经常被自我质疑唬的不敢动笔然后陷入僵局；所以当时忽略后半句的我并没有觉得这是多让人豁然明朗的建议。我们很快转到下一个问题 “觉得报告能写出来的结论都是 common sense 怎么办” 继续讨论。 第二个问题 sloan 用某竞品游戏研究的案例告诉我“要努力找出 Common Sense 背后那些寻常难以洞见的问题与解答”，在这个案例中某竞品游戏的长处人尽皆知，而引出思考的问题则是“那么多款游戏，为什么除了它之外都无法复刻这个优点”。 不过就算有人把这类另辟蹊径的问题挑明了拍我脑门上，我很大概率也会觉得其无解而抗拒去探寻背后的原因：“影响一款游戏设计思路的因素太复杂了，真的可以找到原因吗？” 一如最近不觉得有结论可写的我：“就这？”“真的吗？我不信；我觉得不严谨，我不能写上去” 总而言之，虽然平时究极擅长用各种鲁豫式的问题自我劝退，但我确实可能真的不太擅长找到一些“能够较好地引导自己深潜”的问题；在数据处理之外的思考深度很可能完全不够 cover 目前的研究项目。 之前更习惯的思考方式其实是从“当前情境往前回溯定位问题所在，然后解决/改善”的 Engineering Mindset，绝大多数脑力消耗都侧重于“问题的解决”，而上一个问题的解答又往往引出下一个问题；这样环环相扣下去，所谓“问题的提出”其实是一件很顺水推舟的事情。 这也是我最初听到 sloan 说“想清楚要回答的问题”时不置可否的原因。因为我默认新的问题会伴随着上个问题的解决而出现。当没有新问题被发现时，也就可以结算收尾了。过往经验里令我头疼的 Par 往往是 Bug 出现后的 Debug 环节，最起码在数据分析层面，发现问题并不是一件困难的事情，排查和解决问题才是。 复盘的时候会发现，这个项目中数据分析阶段所有的问题都围绕着一个明确的目的：保证分析结果的信度和效度。而所有的问题都会止步于期望结果的输出；因为走到这一步，分析结果的信度和效度已经足以佐证方法的正确性。 现在看来，在一项研究中过于沉迷方法很可能会带来数据分析侧产出期望的降低，即难以“跳出数据再追求更深一层的结论”。而产出期望降低的后果就是惊觉“数据结果和报告结论间存在 Gap”。 所以先前困于其中不得解的，根本不是“是否应该写成结论”的判断问题；而是“如何就数据结果再行演绎，获得进一步结论”——这个过程与数据分析的关联性并不强；坦诚地讲，很难依赖数据处理方法的改进去获得更清晰的结论。 现在整个报告的撰写已经趋于尾声；回头来看我其实是在偏后期的阶段，才意识到“应该把从数据窥得的结果当做引子，结合桌面或其他研究方法，做更广更深的论证解释或补充延伸”——就是在写报告的过程中，一旦明显感受到捉襟见肘的滞涩感时，就应该去跳出数据分析来考虑的方向。 这套思考方式用来写报告当然也没毛病。谁不想自己的报告逻辑严密抽丝剥茧般层层递进；不仅能回答看官老爷们本来的问题，还能在信手抛出新的问题然后甩一页漂亮的回答震得他们大喊一声卧槽牛逼。 简直事了拂衣去，深藏功与名。","link":"/2020/06/27/%E7%A0%94%E7%A9%B6%E7%B4%A0%E5%85%BB%E6%8F%90%E5%8D%87%E6%8C%87%E5%8C%97-Vol.1/"},{"title":"社会化标签的层次构建","text":"关于社会化标签的文本分析方法. 严格来讲，B站的视频 Tag 并不算人人皆可标注的“社会化标签” （毕竟只有 Up主 可以编辑）。但B站视频标签的自由度远高于 Steam 和 TapTap 上的游戏标签却是毋容置疑的。目前 Steam 和 TapTap 均支持由用户添加私密的自定义标签，但公开的标签基本都是对游戏类型（与玩法元素）的概括；反观B站的视频标签，完全由 Up主 手动自定义，标签的提及次数长尾效应显著，而处于尾部的标签往往缺乏语义规范。 此前曾有研究者通过分析标签的内容， 构建中心性、熵、共现频率、稳定性、描述力等指标对标签的质量进行自动评估。也有研究从标签和主题内容匹配程度来评估标签质量，如 标签和主题词表的相似度或重合率、标签与文本内容关键词的相似度。 我们本来希望通过标签网络来挖掘标签主体的实质性关系，但事实上除了标签冗余的问题，标签间由层次模糊而导致的疏松结构也会造成分析时的噪音。很多学者从语义方面入手为社会化标签添加了层次结构： 为标签词汇进行分类组织 以概念为层次分析对象 结合成熟的工具进行分层（例如Wordnet） 普遍性包容层次理论其中，Heymann 等学者提出了一种基于标签相似关系图的隐含层次结构模型来实现本体的学习方法，他们提出了3个前提假设： 假设一：在原始的社会化标注数据中，标签相似关系图中隐含了概念之间的关联关系； 假设二：存在于标签相似关系图中的关系并不都是有用的。原始标注数据中所包含的标签包容关系图展现了标签间的关系，但是这些关系对于所要导出的本体并不一定都是有用的。可能存在不相关关系和不一致关系； 假设三：本体的概念层次结构越往上，噪音关系越多。 基于以上前提假设，我们按照标签的使用频数从大到小对标签进行排序，即按照标签的普遍性进行排序；并将排序靠前的标签作为上层标签进行层次构建。 标签普遍性排序的基本思想是： 如果一个标签包容其他具有较高普遍性的标签，那么他本身也应该具有较高的普遍性。每一个包容关系将被视作一个互增强关系，而这一互增强关系将正比于该包容关系置信度。 根据该理论，可以通过以下概率方法，试图挖掘出标签之间存在大致上下位关系： 定义一：假设 标签 $t_i$ 和 标签 $t_j$ 的标注资源数分别为 $Nt_i$ 和 $Nt_j$ ，$Nt_{ij}$ 是 标签 $t_i$ 和 标签 $t_j$ 的共现频数，N为标签总数，那么 标签 $t_i$ 和 标签 $t_j$ 的使用支持率为：$$Supp(t_i)=\\frac {|Nt_i|}{|N|}，Supp(t_j)=\\frac {|Nt_j|}{|N|}$$ 标签 $t_i$ 和 标签 $t_j$ 共现支持率为： $$Supp(t_{ij})=\\frac {|Nt_{ij}|}{|N|}$$则我们说 标签 $t_i$ 被 标签 $t_j$ 包容的置信度为$$Conf(t_i,t_j)=\\frac {Supp(t_{ij})}{Supp(t_i)}= \\frac {|Nt_{ij}|}{|N_i|}$$当 $Supp(t_{ij})&gt;0$ 且 $Conf(t_i,t_j)&lt;Conf(t_j,t_i)$ 时，说明 标签 $t_i$ 和 标签 $t_j$ 之间存在共现关系，并且 标签 $t_j$ 相对 标签 $t_i$ 是一个更具体应用。当然也可以从概率的角度来分析，由于关系换算后 $Conf(t_i,t_j)=\\frac {Supp(t_{ij})}{Supp(t_i)}= \\frac {|Nt_{ij}|}{|N_i|}$，对于同一对共现标签，当置信值越小，分母越大，即处于分母的标签其标注资源数就越大；当 标签 $t_i$ 比 标签 $t_j$ 更普遍，在构建层次结构时，我们就把 标签 $t_i$ 设置为 标签 $t_j$ 的父节点。 定义二： 假设 标签 $t_i$ 和 标签 $t_j$ 的使用相似度为：$$Sim（t_i,t_j）= \\frac {|Nt_{ij}|}{Max(|Nt_i|,|Nt_j|)}$$所谓使用相似度，是根据条件概率思想来判断 标签 $t_k$ 在使用过程中，与哪一个属于其尚未标签节点（$t_i$ 或 $t_j$）间的共现频率最大。 为了方便构建层次结构，我们会将标签按照标注资源数从大到小排列。而依次为依据生成的共现数据矩阵中，标签的排序也是从大到小的顺序。当 $Nt_{ik}$ 和 $Nt_{kj}$ 均非零，且 $Nt_{k}$ &lt; $Nt_{i}$ 且 $Nt_{k}$ &lt; $Nt_{j}$ 时，根据包容置信度计算公式，可知 标签 $t_k$ 必定为 标签 $t_i$ 或 标签 $t_j$ 的子节点。 这里的相似度计算公式融入了条件概率的思想：当 标签 $t_{i}$ 发生的情况下 标签 $t_{k}$ 发生的概率，大于 标签 $t_{j}$ 发生的情况下， 标签 $t_{k}$ 发生的概率，即可将 标签 $t_{k}$ 置为 标签 $t_{i}$ 的子节点。 伪代码基于标签的标注资源数，对标签及其对应的标注数据从大到小进行排序。 输入：排序后的标签 $t_0$， $t_1$，…，$t_N$ 和资源间对应的标注数据（即标签总数为 N）。 12345678for(i=1,i&lt;N,i++) if sim(t[0],t[j])!=0： t[j]成为t[0]的子节点for(j=1,j&lt;N,j++) for(k=1,k&lt;N,k++) if sim(t[i],tj)&gt;sim(t[i-1],t[j]) t[j]成为t[i]的子节点 else t[j]保留为t[i-1]的子节点 Case：B站“剑与远征”关键词下的视频标签层次构建 数据说明与清洗：截止1.22 16.03时采集到的B站“剑与远征”关键词下的视频条数去重清洗后共有795条，320个标签，标签所标注视频数呈现明显的长尾效应（如图1）。由于标签的随意性，绝大部分的标签被少量人使用。因此，我们在基于标签的标注资源数进行排序后，选择标注数最多的20个标签进行层次构建，其中 Top20 标签标注的视频数最少为27。 计算两两标签间的相似度矩阵12345678910111213141516171819202122232425262728293031323334353637383940import xlrd, copy, mathfrom openpyxl import Workbookimport numpy# 定义相似度计算函数def sim(a,b): sim=len(list(set(a).intersection(set(b))))/max(len(a),len(b)) return simworkbook = xlrd.open_workbook('Top20标签.xlsx')sheet = workbook.sheet_by_index(0)rows = sheet.nrowscols = sheet.ncolstag_names = sheet.col_values(0)wb = Workbook()ws = wb.activerow_index = 0alltags=[]for row in range(rows): tag_allgames =[] have_games = sheet.cell_value(row, 2).split(', ') # 获取标签对应的游戏，存入have_games列表 for have_game in have_games: # import pdb;pdb.set_trace() if have_game == '' or have_game == ' ': # 如果标签对应游戏为空，跳过该行 continue if len(have_game.split('!@#')) != 2: # 如果游戏名格式不对，跳过该行 continue have_game_name = have_game.split('!@#')[0]# 游戏名为have_game_name tag_allgames.append(have_game_name) alltags.append(tag_allgames) #print(sheet.cell_value(row, 0),tag_allgames) num_list = numpy.zeros((rows, rows)) for i in range(len(alltags)): for j in range(len(alltags)): num_list[i][j]=sim(alltags[j],alltags[i]) print(num_list[i][j]) numpy.savetxt('new.csv', num_list, delimiter=',') 基于普遍性包容层次理论构建标签层次图 用幕布手动绘制orz 别问QAQ 问就是数据结构没学好 不会树的可视化生成 “剑与远征”仅仅是个案，选取Top20关键词来进行层次构建也实属无奈之举，从中能获得的结论是很有限的。 从横向来看“攻略”、“游戏视频”和“ponponlin”等语义不相关的词位于同一层令人迷惑，这是因为该层次结构仅仅从用户的使用习惯出发，根据标签的使用特征来构建。我们不妨这样理解：被打上手机游戏 Tag的视频与 手游/剑与远征 的共现概率更高，且 手机游戏 Tag的使用更为常见。 以此类推，至少我们可以获知： 在具有父子关系的社会化标签之间，一定是父标签的普遍性大于子标签，从中可以反映出资源内容的偏重点。 在标签层次树中执行DFS所得分支与在网络图中执行模块化所得族群一样（事实上树就是最简单的连通图），能够通过标签关系呈现内容趋势。 写在最后互联网上各种用户参与的网页、论坛、社交网络等数据，无意间构成大量具有研究价值的自然标注资源，标签就是其中一种典型的显式自然标注。通过拥有不同专业知识背景、兴趣爱好广泛的大量非专家的互联网用户自发地使用任意自然语言词汇为感兴趣的资源创建标签并与他人分享的过程，采用自底向上的方式汇集用户自由标注的标签，形成社会化标签。 但社会化标签对研究造成的困扰在于：其缺少明显可供挖掘语义关系的来源和具体应用的语境，对于模糊和歧义的标签，很难明确标签的含义。且由于标注的随意性，以及用户的兴趣、专业程度的不同，导致社会化标签没有统一的标准，标签质量层次不齐。 这篇Blog主要基于普遍性包容层次理论来构建社会化标签的层次结构，是最简单的、出于概率角度的考虑。囿于笔者在NLP方面的知识所限，当前的标签层次分析法在实际研究中的支持作用并不明显，初步的想法是从经过模块化处理后的网络图中抽出子模块，再将子模块的标签进行层次建构，更进一步地获得在结论上的支持，而不留驻于原来子模块的网络图这一步即止。 除了确实超出现有能力范围的从矩阵到树的可视化外，笔者的顾虑更多在于：简单粗暴的概率比较是否会掩盖那些更有价值的结论。所以接下来应该会继续从文献中学习提高效度的算法来改善方法~~","link":"/2020/01/20/%E7%A4%BE%E4%BC%9A%E5%8C%96%E6%A0%87%E7%AD%BE%E7%9A%84%E5%B1%82%E6%AC%A1%E6%9E%84%E5%BB%BA/"},{"title":"2019年秋季学习游戏学导论数值部分复习笔记","text":"整理自熊硕老师（xiongshuo@hust.edu.cn）本科生课程《游戏学导论》第十讲“数值之美”的讲义. 战斗力定义 $h_x$ 和 $h_y$ 为玩家和怪物的生命 $dpt_x$ 和 $dpt_y$ 是玩家和怪物的单位时间输出伤害 则 $FC（Fighting Capacity）= h_x*dpt_x$ 要预估战斗的胜利，只需要用 $FC_x-FC_y$ 即可 等同于玩家要战胜怪物，只需要满足$$\\frac{h_x}{dpt_y}-\\frac{h_y}{dpt_x}&gt;0$$ 幂函数 前期容易后期难是普遍的经验值递加设计原则，所谓 $x^i$ ，$i&lt;1$ 时具有这种特性； $i&gt;1$ 造成的连锁递增效应是用来奖励的上好措施；某些需要积累到一定程度才能体现出的优越性的属性设定往往需要用到 $f(x)=x^1(i&gt;1)$ 的先缓后急特性； $f(x)=\\frac{1}{x}$ 常常以 $\\frac{a}{b-x}$ 的形式出现，常用来实现具有临界值的属性设定，且 $x$ 多有取值限制，需要很好的前期规划。 幂函数的应用： 升级经验 = $ceiling(1000 * 等级^{0.66})$ //ceiling=向上取整 消除类休闲游戏（如宝石迷阵）：COMBO得分 = $100本次宝石个数2^{combo次数}$ 魔法攻击 = $智力值+int^2\\frac{智力值}{10}$ //int=向下取整 $f(x)=\\frac{1}{x}$ 的应用： 攻击速度 = $\\frac{50}{200-\\frac{250-敏捷-\\frac{灵巧}{4}}{50}*（200-基本速度）}$ 命中率 = $\\frac{100}{1+(150-敏捷)}$ 魔法回复(点/秒) = $2+(2+\\frac{精神}{50})^2$ 丢骰子的问题 一个6面的骰子，丢一次每个面出现的几率是 $\\frac{1}{6}$ ，要求出现6的概率达到95%，应该丢几次骰子？$$1-（1-\\frac{1}{6}）^x&gt;0.95$$ 套装收集问题某套装A由n件装备组成：$A=a_1,a_2,…,a_n$ 每件装备都有某Boss掉落且每次只掉落一件，每件装备的掉落概率都有概率向量p给出：$P=(p_1,p_2,…,p_n)$ 为收集齐此套装的n件装备，平均需要杀多少次Boss？ 装备升级问题 武器为1～3 级时，升级概率分别是 95% 90% 85%。升级成功则级别加1，升级失败，保持等级不变。 武器为4～6级时，升级概率是 80% 75% 70%。升级成功则级别加1，升级失败，降1级。 武器为7～9级时，升级概率是 65% 60% 55%。升级成功则级别加1，升级失败，爆到0级 一次升级概率矩阵hexo的markdown语法居然不识别矩阵(:з」∠) 升级概率计算 升级概率决定的收入在前面所描述的升级系统基础上： 每次升级所需费用标准为10元游戏单位货币，玩家拥有1500元单位游戏货币，但玩家拥有1500元单位游戏货币；当用完这1500时，武器停留在每个级别的概率分别是多少？（即升级150次后各自概率为多少） 每次升级所需费用标准为当前武器级别×10元单位游戏货币，玩家拥有1500元单位游戏货币，当用完这1500单位游戏货币时，武器停留在每个级别的概率分别是多少？（0升级1不要钱，1级升级10元，2级升级20元） 这两个问题人类无法计算，同样依赖编程求解。 胜率问题：Elo Rating System多个战斗单位的战斗过程：兰彻斯特 多人战争的一个趋势，就是起初的优势会随着战斗过程的进行而被逐渐扩大，因此多人战斗过程绝对不是直接采用承受乘以输出，然后相减这样简单，或者说，我们要换用一种方法来对FC进行计算。现在就用一个基本的数学模型来进行说明。 基本假设 假设任何一个单位都能够连续不停的对敌方的单位进行攻击直至被摧毁或者战斗结束 双方都采用最优的战斗模式 比如说一方每个单位的生命为100，那么在受到240点伤害时， 2个单位死亡，还有一个单位受到40点伤害，而不是60个单位受到4点伤害或者80个单位受到3点伤害 每方的攻击力与战斗单位的数量成正比 推理过程与微积分使用案例现在一方有 $x_0$ 个单位，另一方有 $y_0$ 个单位（假设 $x_0&gt;y_0$），杀伤力为 $p$（$p$为单位时间输出伤害与战斗单位生命的比值。（比如《星际争霸2》 中，陆战队员对射，每个陆战队员攻击力为6，生命为45，那么杀伤力就是6/45） 那么战斗过程中的微分方程为：$$\\frac{dx}{dt}=-py$$ $$\\frac{dy}{dt}=-px$$ 考虑初始条件，$t=0$ 时，$x=x_0, y=y_0$ 求解微分方程可以得到$$X = \\frac{X_0+Y_0}{2}e^{-Pt}+\\frac{X_0-Y_0}{2}e^{Pt}$$ $$Y = \\frac{X_0+Y_0}{2}e^{-Pt}-\\frac{X_0-Y_0}{2}e^{Pt}$$ 当 $t=\\frac{1}{2P}ln\\frac{X_0+Y_0}{X_0-Y_0}$ 时，Y=0，Y方被消灭，此时X方还剩$\\sqrt{X_0^2-Y_0^2}$ 兰彻斯特平方定律在任何时候，双方的人数平方的差距不变，假设单个单位的战斗力为FC，那么对于ｎ个单位，其战斗力与 $n^2*FC$ 成正比。$$X_0^2-Y_0^2=x_t^2-y_t^2$$ Game Refinement Theory将游戏进程模拟成为物理活动，以描述其在大脑活动内的过程。同时考虑游戏的数学复杂度，以及博弈策略集。用于宏观把握游戏的节奏设置与可玩性评估。 游戏复杂度由$B^D$给出 B是可能移动的平均数（博弈策略集） D是平均游戏长度 忽略数学推导过程与物理建模描述，我们需要寻找的是在游戏运行时，在人脑中的加速度，即Refinement Value 洗练值。 有意思的是，大部分成熟游戏的R值在固定范围内。 B/G D/T R Chinese Chess 39 85 0.073 Chess 35 80 0.074 Go 250 208 0.076 Japanese Chess 80 115 0.078 Soccer 2.64 22 0.073 Basketball 36.38 82.01 0.073","link":"/2019/12/28/%E6%B8%B8%E6%88%8F%E6%95%B0%E5%80%BC%E5%85%A5%E9%97%A8/"},{"title":"面试中项目经历回答思路","text":"说得到不代表做得到（咸鱼握拳.jpg） 上个月面 iMUR，从业务面到总监面的大部分时间都在聊包括暑假实习在内的项目经历。“极其看重对一段研究经历的完整介绍”，暂且不论面试官如何追问，“有的放矢缓缓道来”是我觉得比较好的陈述状态，但遗憾在两次面试都没有做到至少先让自己满意的程度（拍大腿.jpg） 归根结底还是平时的反思+回顾太少了惹！语言表达能力欠缺+临场发挥不好只是表象辣。 接下来分【平时-项目中】、【面试前】及【面试中】三个阶段阐述。 平时-项目中 信息：尽力获取 Full Picture+跳出来俯瞰项目 细节：记录坑 [印象笔记]+总结整理[博客] 面试前 项目背景 按项目生命周期切分各个环节，需要想清楚： What How（#项目细节 Association Difficulty&amp;Solve Pre-&amp;Post-（#论环环相扣的重要性 …… 客观成就&amp;主观收获（cue其他相关经历 面试中一个可能不错的 Storyline 概述（项目+背景+投入时间+团队成员+担当职能） 过程讲述（突出重点与细节） 总结 part1：遇到的困难+解决思路：[1、2、3… 总结 part2：做的好+不好的地方（紧跟着 之后做了什么弥补&amp;如何改进的思考） 总结 part3：收获与意义 1+2 与 3+4+5 的时间对半分就比较ok~ 一个栗子这是我简历中 [实践经历] 的一段： 未来信号空间站”线上商业研究实践训练营 - 高校研究员 腾讯互娱市场与用户研究部 2018年10月 - 2019年10月 在腾讯互娱用户研究经理的指导下连续两期从事长达12个月的泛文娱领域前沿商业研究，合作互动叙事剧本评测、游戏 IP 运营方法论等8 个深度课题，累计独立撰写超过40个文娱领域前沿趋势小报告约六万字，个人排名连续上升后稳定在20%，二期六个月总排名3/51。 在面试前准备的时候可能会就与岗位匹配的1-2个小型课题及相关趋势小报告重点准备~ 那在面试中当问到“你能不能介绍一下这段经历？”的时候，就可以这样表述： 它是腾讯互娱市场与用户研究部与玖久咨询一起办的一个高校学生参与的线上实践活动，每期六个月，我是从18年10月到19年10月连续参加了两期。每周都会独立撰写趋势洞察报告，比如去年的互动剧风口，还有观察类真人秀，包括我个人可能比较擅长去从一些游戏的玩法或玩家群体切入去进行分析。那除了独立撰写报告的部分之外就是小组合作的课题了，大家都是线上远程合作去完成一些文娱方向的课题，像xxxx、xxx等。 那在撰写趋势洞察报告的时候，其实会花很长时间去从各种渠道获取有价值的信息，然后提炼观点；主要从趋势背后的变化、变化可能带来的影响，以及如何在业务上利用趋势去论述。那在小型课题的研究方面主要是确定研究框架然后分工合作完成。 遇到的困难：很多的瓶颈期，五十几周到最后感觉自己写的东西没有什么新意；a.保持对信息渠道的遍历，写不出来也要多看、b.和朋友交流、c.多推敲多问自己“为什么”etc. 最大的收获：a. 策划视角朝研究视角的转变，对未来职业的思考；b. 很多新传专业的同学，跳出学校视角对专业的理解；c. 洞察力/笔力/分析能力（框架先行）","link":"/2019/11/18/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86%E5%9B%9E%E7%AD%94%E6%80%9D%E8%B7%AF/"},{"title":"《隐形守护者》选项设置及故事结构分析","text":"2019年秋季学期《游戏学导论》Report 3. 《隐形守护者》确实是一部走心的诚意之作——用14个小时通关三条线并遍历完所有选项达到100%探索度后的我也不能免俗地要说上一句“这58块钱花的值”。《隐形守护者》在文案台词、画面乃至配乐配音方面都有不少可圈可点之处。很多转折稍显生硬的台词，在配音老师们非常到位的情绪拿捏下代入感是非常强的；纯子咬字生涩的汉语也体验出制作团队对细节的重视。作为《游戏学导论》文案叙事：结构与选项 课后的报告，本文旨在从选项设置和故事结构发展两方面对《隐形守护者》的出彩之处展开分析。 选项自《隐形守护者》之后各大平台纷纷试水互动叙事。如果说剧本是一款互动叙事作品面对受众时赖以输出的内容根基，那互动形式就是在剧本呈现方面起到重要作用的核心要素，未必越复杂越独特的形式效果就越好。《隐形守护者》中的大部分互动都是剧情节点的选项，少部分时候用模拟操纵物体与声音提示增强交互体验。好的选项不管是在玩家流程还是剧本结构里都当得起“正合时宜”四个字；另一方面，选项的设置关乎玩家诸如剧情理解、情感触动等体验维度，不管是画蛇添足过犹不及的多余选项，还是轻描淡写不痛不痒的无用选项，都是玩家体验时的减分项。“恰如其分”的选项不能不说颇考验制作人在游戏性方面的设计功底。 逻辑的强解释性《隐形守护者》中有很多选项， 譬如开局找内奸、与斧王喝酒、推理斧王和荣银海的阴谋时都是可以找到并遵循某套自洽的逻辑并通关的——这套逻辑作为解释选项合理性的原因，即便是跳出游戏后，以上帝视角俯瞰时都可以被认为是主角不可避免的情境与别无他法的最优解。 这类选项无所谓玩家本意如何。除非玩家不想继续游戏，否则都必须试出所有选项的正解。鲜少有玩家能一次性通关，但当大家都通过之后回头来看，会觉得“的确如此”：在面对连环拷问时，确实没有什么能比“先用已知为真的信息加深对方信任程度”来确保最后的谎言能够蒙混过关的路子了。玩家其实是在探寻答案而非做出决策，或者说游戏让玩家代入体验这段紧迫剧情的“故事性”；玩家未必会认同，但一定是信服的。 这种选项十分依赖作者对情节的塑造能力，也相对来说更能体现互动叙事作品的编剧水平和剧本深度。和推理小说烧脑的桥段一样，即便是没有切分成轮流交手的回合选项，受众也能大呼过瘾。而选项的意义就在于带给受众更设身处地的思考与感受。 有迹可循的推理vs无凭无据的悬念有一部分的选项结果是即时反馈的，立刻就能告知玩家选项的意义；而另一部分则属于草灰蛇线伏延千里的那种，会对以后的结果产生深远的影响而非当下。 站在玩家的角度，面对某一部分选项时读者能用充分的线索或可靠的推理来确定某个答案，如开篇接收到方老师关于图书馆的见面地点暗示，又如纯子的指甲油，这类选项前后印证，通过让玩家调用已有认知储备来解决问题，进而赋予玩家成就感。 而另一部分选项玩家几乎很难从之前的游戏中获得决策依据，只能凭感觉选或猜测。玩家会感到茫然，但恰恰是这类“不够顺理成章”的选项为游戏留下悬念。但这类选项需要后续的剧情给予回应，以免玩家的期待落空，累积失望。 精巧的隐喻在关键的选项中，隐形守护者选项的逻辑是能说得通的。除了上述中提到的玩家接受度颇高的最优解，一些影响深远的选项与其导致的结果，游戏通关后还能掩卷咂摸。制作组的隐喻不仅体现在台词上，于选项的设置上也是构思精巧。知乎上一个问题 为什么隐形守护者里，信仰不坚定选择救晓曼的肖途反而走了红色芳华线？（https://www.zhihu.com/question/315339143）的回答里谈到了肖途与女主的“相互救赎”： 隐形守望者有一条很隐秘的线，就是关于五个女主的（包括顾君如）。你解脱了顾君如，她让你完成了任务，你救了晓曼，所以晓曼给你信心，度过三年牢狱，你救了纯子，所以纯子记录你的故事，为你洗脱冤屈。你从银狐手里挽救了望舒，她陪你度过余生。整个芳华线缺一不可，你是在挽救她们，她们也在挽救你（这一点吹爆）。对应的，你没有救下晓曼，所以不可避免的走上丧钟线or美丽世界线。 为什么隐形守护者里，信仰不坚定选择救晓漫的肖途反而走了红色芳华线？ - 郝心音的回答 - 知乎 https://www.zhihu.com/question/315339143/answer/619757926 ​ 有些选项啊表面上是在推剧情，实际上是在考验人性。 ​ 这些经得起推敲、也值得深思的选项立起了剧本高度，也是我最喜欢的文以载道：于无声处听惊雷，言有尽而意无穷。 故事结构自从亚里士多德以来，所有叙事理论方面的专家都在强调结构的重要性。（杰克 · 哈特《故事技巧：叙事性非虚构文学写作指南》） 逻辑是组成部分之间的必然联系，而结构比逻辑更容易看得见、摸得着。 不管是中国诗词的起承转合，还是日本能剧讲究的序破急，抑或是美国好莱坞的三幕式结构，都是勾勒在一条叙事弧线上的——形状就像是向右偏离的正态曲线。“在叙事性写作方面，很少有作家能够明白故事线应该是呈弧线形的，不仅仅是由开头、中间和结尾组成，还有一连串的事件带领着读者前行。我读过很多单调乏味的作品，事件依次发生，故事本身并没有丝毫动感。”（《美国佬》杂志前任编辑吉姆 · 科林斯在2001年尼曼叙事大会上发表的观点，收录于2002年春季号的《尼曼报告》） 一条真正的叙事弧线会随着事件向前延伸，看起来就像一股即将撞碎的波浪，蓄势待发，下一秒就要迸溅成美丽的浪花。（杰克 · 哈特《故事技巧：叙事性非虚构文学写作指南》）时代背景波澜壮阔，《隐形守护者》的卧底潜伏更是曲折。在接下来分析故事结构时，笔者将首先按照游戏章节拆解叙事弧线，而后分别对故事的转折点与伏笔等结构内部的要素进行探讨。 叙事弧线起：布局 序章：回国后与方敏的羁绊、在恩师授意下接受党组织任务，开启双面生涯 第一章“太阳之影”：进入亲日报社、开始逐渐获得反派信任（带纯子逛街）、遭遇叛变老师身殒后设计锄奸（与方敏的羁绊加深） 第二章“狩猎者”：在刺杀吴明达时朝小顾开枪、拜访兴荣帮、迎来李峰与庄晓曼的考验 《隐形守护者》故事的序章、第一章“太阳之影”和第二章“狩猎者”作为开局起势，肩负着一个特定而又关键的任务：对接下来的所有事情进行布局。 我们可以看到相关内容被分解成几个重要的事项：与方敏间的羁绊、以恩师的死亡为代价获取武藤眼皮开始虚与委蛇暗度陈仓、成为孙先生的下线、因小顾之死接触李峰与庄晓曼，这些都为之后在主角身上发生的事情织起一张利害关系网。 情节尚未展开，但就是在这里，玩家意识到：主角身负误解与不得已，与上级单线联络，在武藤公馆周旋时又遇到军统间谍；并且开始关心接下来会发生什么。在危险来临之前隐患初现，玩家对处于重大危机之下的主角越是同情，在发生改变时就越关心。玩家越关心，故事的效果就越好。 承：反应 第三章“生死途”：营救商贸团（与庄晓曼发展出过命的交情） 第四章“修罗场”：营救商贸团后续摆脱内奸怀疑、遭上线背后捅刀入党证明被烧毁 第五章“菊与刀”：浅野与武藤的站队问题、主动寻求背靠资源 红色芳华&amp;美好世界线-第六章“至暗抉择”：火车上向第二号示警、与晓曼并肩刺杀浅野 先前布局的剧情是任务驱动的，通过一系列场景也让主角在游戏中意识到“出现的新的东西”。它引出新的追求、出人意料的需求、一种召唤或是一次旅程，这些通常都是令人恐慌或充满挑战性的。（拉里 · 布鲁克斯《故事工程：掌握成功写作的六大核心技能》） 而在这一部分，主角通过行动、决定或犹豫对敌对势力做出反应，继续负重前行。 在前一部分受刺杀吴明达的任务驱动时，玩家无论如何努力都无法保全小顾学妹。这是因为从第二部分开始，玩家扮演的主角才和敌对势力走上一条不可避免的决战之路，敌对主角对主角要做的、要得到的、要实现的、或者要改变的东西加以阻挠，防止其达到目的。 欣慰的是，虽然恩师与小顾之死让主角和玩家逐渐意识到牺牲在所难免，但在此之后玩家所扮演的主角却在与虎谋皮、保证“活下去”的基础上，努力地追求“不泯灭的人性”。 “不泯灭的人性”——其实就是主角漫长潜伏生涯里的最高目标。 隐形守护者中看似最重要的是潜伏，其实最重要的是人性。除了不能把枪给小顾那次，其余每次你按照着人性选，几乎都不会错。 你下车了，也就意味着为了和组织接头，你放弃了晓曼的性命。看似你坚持了信仰，其实你失去了人性。 还有很多地方也是如此，浅野找你揭发武藤的时候，如果为了更好地潜伏，你应该离开失势的武藤而投向浅野。但你和武藤之间的友谊左右了你的选择，最终也救了你的命。放走徐先生也是如此。把胡蜂的身份给晓曼也是如此。 相反地，游戏中凡是那些为了所谓大义而放弃人性的选择，一般都没什么好下场。 为什么隐形守护者里，信仰不坚定选择救晓曼的肖途反而走了红色芳华线？ - van斯摩格的回答 - 知乎 https://www.zhihu.com/question/315339143/answer/644508160 于是在第二部分中，我们看到主角在营救澳门商贸团时否定了庄晓曼的最初方案，努力找到了在当时情境下不可能更好的最优解；在浅野和武藤站队的选择上思考局势；在武藤怀疑的时候不丢下火车上的庄晓曼。 在追求目标的过程中，玩家逐渐看到并且关心主角真实性格的展现和逐层剖析。 转：进攻 红色芳华线-第七章“大风起兮”：与斧王周旋、高源初露端倪 红色芳华线-第八章“游戏的规则”：斧王插手兴荣帮内乱、绑架纯子并祸水东引 红色芳华线-第九章“远东残阳”：内乱波及逃亡、码头与高源对峙落下风 在决定留在火车上与晓曼并肩作战并为第二号所救后，主角开始向眼前的障碍发起进攻。后期混战之局势力林立牵涉复杂，部分如地下工作者陆望舒、斧王冯一贤、设局者徐先生、军统间谍高源等的新内容被加入到故事中，成为主角由第二部分的“流浪者”、“响应者”转变成为积极主动、具有进攻性的“战斗者”的催化剂。于是我们看到主角在兴荣帮内乱波及到自己时毅然烧毁资料，并察觉高源异样宁死不服软。 接下来最后一个谜团出现在这部分的结尾处，即纯子失踪之谜，第四部分紧随其后。 合：解决 红色芳华线-第十章“极恶非道”：解决兴荣帮内乱、营救纯子 美丽世界线-第七章“丛林法则”+第八章“美丽世界”：误杀第二号、叛归军统、一黑到底（ 枪毙陆望舒发国难财平息学生运动操控民意，桩桩件件，不择手段，毫无下限） 扶桑安魂线-第六章“扶桑安魂曲”：异乡孤魂、残杀无辜 从这部分开始，故事内就再未加入新的信息。所有主角需要了解、处理或与之共事的一切都已经出现在故事中了。 在红色芳华线中，主角成功营救纯子——在纯子被绑架这个事件的解决中，他并不是次要的旁观者。 而在背弃了信仰的日本及军统线中，主角同样为了达到目的，做了必须做的事情。只是这时候他的目的变成了：偷生。 故事峰回路转，叙事弧线上升下降。但需要注意的是，希望的新生与幻灭、谜题的设定与揭晓、悬念的形成和解开，可以出现在故事从头到尾的任意阶段——可以将它们画成一条曲线，并向上缠绕在叙事弧线上。 私以为游戏剧本创作并不必恪守精确而严格的结构规则，这是因为相比影视剧或小说，游戏中的元素更为复杂。而这些元素是如何相互联系、相互作用，又是如何做到彼此平衡、相得益彰的，故事结构的内部运转才是关键。 故事转折点的作用诚如上文所说，故事中的曲折常有但转折点不多。每个转折点都是一个情节转折，但并非所有情节转折都构成故事上的转折点。一个极端的例子就是在最后一张用自己换下陆望舒但并未被武藤志雄处死，并非转折点是显而易见的。 转折点的场景十分重要，支撑着整个故事的结构，也对故事中的其他场景也起着关键作用。 转折点 章节 剧情 复仇的子弹 第二章 狩猎者 庄晓曼因小顾之死在酒吧拷问主角真心，最终留主角一命 列车上的去与留 第六章 至暗抉择 面对浅野的怀疑和疑似组织的接头人，做出下车或留在车上的决定 “复仇的子弹”将故事的语境由布局模式转向反应模式。如果说主角杀小顾学妹还是在任务驱动下的别无选择。那在庄晓曼给主角留下那颗子弹后，主角开始采取措施作出反应。张力和重大危机在布局阶段就会出现，但冲突的实质和暗含的意思在这里才揭示出来。 这次为了完成任务杀的是毫无主见的小顾学妹，那以后呢？是不是不惜一切地完成组织任务就是合格的潜伏者了呢？——并不是。这个转折点之后的主角让我们看到了改变，营救商贸团不必以方敏的生命为代价，在火车上用武藤的杀手吸引浅野注意，主角对“人性”的具体追求自此而始。 而在经历了列车上的去与留后，只要主角没有选择沦丧信仰，这个转折点之后就是主动进攻的时刻——即便回到上海又是一轮新的风暴。斧王的连环拷问是敌对势力本质和势力的又一次体现，而且比之前更加骇人——主角的信仰与坚持也更加无法动摇。 最后顺便摘录一段关于转折点在创作角度体现的作用，来自拉里 · 布鲁克斯的《故事工程：掌握成功写作的六大核心技能》 通过设计这些关键的转折点场景，熟悉它们的情况并掌握使故事流畅的方法。理解需要为何种场景设置转折点，让它们产生成效，并且将它们连接在一起，你就成功地设计好了故事架构，完成了小说或剧本一大半的工程。 无论在创作的什么阶段，你都可以朝着转折点或者从转折点出来进行创作。由此设置场景，然后再从场景推动故事发展。 不依赖伏笔的高潮情节在某些情况下，作者暗埋一个又一个伏笔，然后通过某一个导火线把所有伏笔轰然炸开，引爆高潮情节。这种现象在长篇连载的网络小说中尤其常见，即用伏笔吸引读者追看，用高潮赋予读者爽感。 但《隐形守护者》之于玩家体验的定位并非“爽感”，作为一款买断制的游戏也没必要指望用悬念情节吊着玩家。一部分伏笔为选项的正解提供线索，是玩家成就感的来源；另一部分伏笔是制作方重视细节的产物，更是无数玩家游戏之外的意难平。 不依赖暗埋的伏笔引爆高潮，那么《隐形守护者》是如何塑造高潮情节的呢？ 高潮 章节 剧情 学联遭叛，恩师身殒 第一章：太阳之影 学联遭到叛徒背叛，方老师和学联学生被控制。方老师用命换得武藤志雄对主角的信任。 学妹的绝望 第二章：狩猎者 在执行刺杀吴明达任务时，主角将保护汉奸吴明达的小顾学妹杀死，并将其嫁祸成杀害吴明达的凶手。 胡队长的指控 第四章：修罗场 为营救商贸团而栽赃日方人员的计划成功后，主角接受胡队长的指控与武藤的怀疑 密室的陷阱 第四章：修罗场 从武藤公馆解职回到图书馆后，在密室被孙氏父子袭击 刺杀浅野博文 第六章：至暗抉择 在列车上交出武藤刺客换取浅野信任，并刺杀浅野 “第二号”之问 第六章：至暗抉择 在第二号佯装军统人员拷问时选择保全庄晓曼 冯一贤连环五问 第七章：大风起兮 在冯一贤追问下虚虚实实拒绝承认地下党身份 营救方敏并出逃 军统线-第八章：美丽世界 用舆论打压方敏后良心发现，营救方敏并逃亡 上表列出了一部分剧情高潮点。笔者倾向于《隐形守护者》大部分情况下用一组角色的立场冲突与性格特质来塑造高潮情节。谍战题材各为其主立场冲突是常态，性格特质体现的比较明显的有懦弱没有主见的顾君如、自私叛党的孙氏父子、笑里藏刀的冯一贤等。尽管可以找到这些高潮情节与此前故事的关联，但还远不到专门揭开先前伏笔的程度。 这种高潮情节辅以能交互设计（如限时的选项）往往善于“唤起玩家的感动”，甚至让玩家会对角色产生强烈的情感依附。“这样一来，前面与各个相关的章节（相遇、角色的过去、与角色互相帮助等）将在玩家的心中更加鲜明，玩家对角色倾注的心思与感情也将更加清晰。”（佐佐木智广《游戏剧本怎么写》） 写在最后笔者在去年这时候曾有幸参与 i-MUR 高校研究员的互动叙事剧本评测课题。剧本评测从设定、角色和故事三个维度进行。以当时的评判标准来看，《隐形守护者》在“情节”和“交互”部分都能给到最高分。 情节：角色目标明确，重大抉择充满压力感。重点情节铺设具有情理之中、意料之外的效果，伏笔与呼应相扣，故事价值基线明晰。 交互：剧情选项密集，分支结构复杂多变，且分支包含大量非重复情节。拥有众多让人印象深刻的压力选择。结局众多。 来源：i-MUR（腾讯互娱市场与用户研究中心）《互动叙事剧本评测标准》 通关后回头来看，作死的行动千千万，能成功活下去的路却只有一条。严格来讲，《隐形守护者》并没有交给玩家任何发挥主观能动性改造世界的权利（参见橙光游戏《官居几品》） ；玩家表面上看似能影响故事走向，实质上却是在剧情提供的开放空间内试错和碰壁。但如前文所述：《隐形守护者》不是升级流爽文，它的内核其实是“坚守”，且在顾君如之死后就明确了“人性高于党性”的追求，屠龙的少年只有这一条容不得半点行差踏错的路走到头，才不会变成恶龙。从这个意义上来说，游戏的机制更倾向于线性解谜而非非线性养成。 但笔者丝毫不怀疑试错和碰壁是《隐形守护者》中能够让玩家代入并切实感受到九死一生潜伏艰险的最佳策略，也是和谍战题材匹配度最高的情感体验方式。其他互动叙事作品中广受称道的开放世界，放在谍战题材里极大可能会分散玩家的核心体验；各种花式死亡用于不合适的题材也可能会让玩家觉得选项敷衍了事。 年初的《隐形守护者》是国产游戏的一次全新尝试，《隐形守护者》的制作组在某种意义上是和剧中角色一样的先驱者：“在娱乐至上的环境下，很多人依然希望探讨严肃话题，而将严肃话题引入的载体可以是娱乐性的。” 时至今日，笔者依然坚持“游戏设计法无定法”的观点，没有一款游戏能通过复制前作的成功之处而后来居上。但无论如何，前人开辟的道路，后人没道理越走越差。 “前人风骨点为灯，少年烧魄赴以追”。 当如是也。","link":"/2019/12/05/%E9%9A%90%E5%BD%A2%E5%AE%88%E6%8A%A4%E8%80%85/"},{"title":"1221-1226 董晨宇老师论文阅读笔记","text":"非常喜欢董晨宇老师在社交媒体方面的研究~ 复媒体时代的媒介意识形态与媒介转换行为 当一种媒介进入到日常生活中，我们究竟会如何定位它应该扮演的角色？如果这种定位暂时还没有达成广泛的社会认同，又对我们的生活与交往产生何种影响呢？ 再中介化（Remediation）再中介化（remediation）：新媒介对旧媒介的重塑 任何一个媒介都不是孤立存在的，它的产生必须建立在以往媒介的基础之上，它的发展也必须植根于媒介融合的环境之中。 人类本身也存在于这一媒介现实中，并且透过这一逻辑重塑媒介认知。我们对一种新媒介的认知，是建立在对旧媒介的理解之上。 因为在临场感和真实性方面，摄影术完成了对绘画作品的重塑和升级 第二序位信息（sec-ond-order information） 每一种媒介都蕴含着某些社会文化的前提。对于传统媒介（例如面对面交流、书信等）所蕴含的第二序位信息，人们拥有大致相同的理解。但是，新媒介的到来会将既有的序位打乱、融合、重新洗牌。在最初的一段时间，人们还没有形成共通的使用规则（如同人们还没学会在照相机前保持微笑），因此媒介使用而造成的误会与冲突就在所难免了。 媒介所蕴含的，更多是一种在人与技术可供性之间彼此塑造出来的情感和道德信息，有趣的是，这与“媒介决定论”的视角正好相反，而是一种典型的社会塑造视角 （social shaping perspective）。 复媒体：驯化媒介技术复媒体强调用户对媒介可供性的选择性利用，看他们如何通过媒介转换来管理情绪和人际关系。 用一个比喻来讲，这种视角很像我们对动物的“驯化”（domestica-tion）。这就相当于把一只野猫，驯养成可以趴在你电脑旁看你打字的家猫一样，我们也会把新的媒介技术放置在我们具体的日常生活中进行改良。这也就解释了为什么一种新的媒介产品究竟会如何被人们所使用，往往和设计者最初的设想有很大的不同。 （我好喜欢这个比喻呀=v=） 因此，我们在理解一种媒介的社会化过程时，也不能忽视技术功能之外，更加重要的文化因素。 贫媒介、富使用——互联网中介化交往中的情感补偿贫媒介：线索滤除取向（cues-reduced perspective） 人际传播研究方面，贝格尔与卡拉布雷斯在 1975 年便提出了著名的不确定性减少理论（uncertainty reduction theory）。人际关系的发展是通过不确定性的降低而不断深入的。 中介化交往就显得更加匮乏一些，我们在降低对彼此的不确定性时，也要花费更多力气。 媒介丰富性理论（media richness theory）：达福特和肖特基于媒介在四个方面的特质，即媒介反馈速度、多线索沟通能力、语言使用能力和情感传递能力，将媒介分为富媒体和贫媒体两类。贫媒体更适合传递功能性的信息，富媒体更适合传递相对复杂的信息。 不管是线索滤除的研究视角，还是具体到媒介丰富性理论，都很容易被指责是一种技术决定论（technological determinism）的研究。 也就是说，它将交往的逻辑简化为这样一种因果关系：人与人的情感沟通是否顺畅，要取决于媒介技术是否提供了充足的社交线索。如果媒介在情感传递能力上是贫瘠的，那么，人的情感沟通就是困难的。显然，这种思路忽略了科技和文化互动，以及形成科技的文化环境，它在脱离情境的情况下解读技术影响力，却很少对具体的历史、文化或社会关系感兴趣，更不会关注人们对于媒介的创意性使用。 富使用——中介化传播环境中的情感补偿 标点符号的创意使用 文字的创意性使用 视觉方言（eye dialect） 情感的通货膨胀/情感的廉价化：在中介化交往中，情感表达也在经历一种类似于通货膨胀的发展。强烈度的情感淘汰弱烈度的情感，并为后者赋予了一种完全不同的文化意涵。 为了克服情感表达中的不确定性，人们就会采取一种更具烈度的方式进行表达，在这个过程中，语言的所指，也就是它所表达的意义，便会处于一种趋向于衰退的不稳定的状态。 在网络空间中，永远都不会形成稳定的标准数字语言（standardized digital language）。 社交媒体中的“液态监视”与隐私让渡 当监视以一种流动性的状态在现代社会中蔓延时，便引发了一系列看似矛盾的社会现象——社交媒体用户一边诅咒监视者，一边充当监视者；一边担忧自己的隐私遭到泄露，一边却又在默许让渡属于自己的部分隐私。监视者隐没于信息的洪流，不再清晰可见；千千万万的社交媒体使用者们却在摸索中搭建起了属于自己的瞭望塔。 鲍曼和里昂在《液态监视》（Liquid Surveillence）一书中认为，我们正处于“后全景监狱时代”（post-panoptical）。 去中心化 监视界限的弥合 大多数人都会或多或少主动“交代”自己的信息，形成一种参与式监视（participatory surveillance） 隐私让渡本质上是一种社交回馈（reciprocal activity）行为，或者进一步说，是一种自我线上名誉（on-line reputation）的管理行为。 分享什么实际上是一种社会学习的过程，也有学者将其比喻为“隐性课程”（hidden curriculum）。隐性课程原本指的是那些学校以间接的、内隐的形式呈现的课程，主要目的是向学生灌输社会规范、价值观、信仰等方面的内容。放在互联网语境下，这种“隐性课程”的讲授者则来自各个领域，而他们讲授这种课程的目的，则在于让学习者少犯甚至不犯社交错误。 另一种决定分享什么的策略被称为想象监视（imagined surveil-lance）。 如果说“分享什么”聚焦的是信息生产，那么，“如何分享”更多聚焦的则是信息流通。不少学者都认为，在互联网时代，隐私的定义不仅仅应该基于内容，更应该基于它的流动渠道。用更直白的话来说，当我们关注网络隐私时，更多应该关注的，是人们如何控制信息的访问权，以及如何确保信息在适当的时机流向正确的对象。 社交隐写术（Steganography） 线上评分机制：网络社会的信任乌托邦？ 分布性信任体系希望为每个用户赋权，激发不同用户的多元见解，但它呈现的结果却是高度正面偏见的评分，和语言极度贫乏的评论。 线上评分之所以会出现这种J型分布曲线，是因为消费者存在购买偏见（purchasing bias）和汇报偏见（under-reporting bias）。 线上评分的生产、传递与接收过程，恰好对应着说服研究中经常关注的三大主题，也就是信源（source）、信息（information）和接收者（receiver）对传播效果的影响。 线上评分在多大程度上影响消费者的决策行为，部分取决于消费者对产品的卷入度（personalin-volvement），即对产品的关注度和熟悉度。 心理学中的精细加工可能性模型（Elaboration Likelihood Model）：研究者发现，一个人在获取和解释信息时，会从两种不同的思考路径中进行挑选：中央路径和边缘路径。采用中枢路径的人会在形成态度之前，批判性地思考与问题相关的论点，而采用边缘路径的人则无须太多认知努力，主要依赖一些较为浅显和外在的因素形成态度。 社交媒体中的哀悼行为与社会规范 社交媒体中的哀悼和悲痛表达既是一个新巧的研究话题，但同时又容易显得缺乏理论纵深感和获取关注的底气。 上世纪 70 年代中期开始，情感逐渐进入社会科学研究领域的视野中心，有学者将这一过程称为社会学的“情感转向”（affective turn）。在此之前，情感问题一直被社会学界忽视，其中重要原因之一是当时主流的社会理论强调“情感中立”，情感一词颇受遮蔽，以至于成为社会学的边缘性话题。 基于对美国航空服务人员的田野调查，阿莉·霍克希尔德（Arlie Hochschild）完成了《被操控的心灵：人类情感的商业化》（The Managed Heart: Commercialization of Human Feeling）一书。 grief/bereavement/mourning：它可以是一种面临失去时经历的主观情感体验，也可以是一种社会规范制约下的表达与行动。 我们的主观情绪被社会文化左右，她将情感比作一种“通货”，而情感规则（feeling rules）则是其交易流通的指南，每一种关系、情境和角色下应“交付”的情感都在其中被标好了价格。 社交媒体中的哀悼表达要求一种“边界感”。 哀悼与日常使用的区隔 观众的边界与与社交媒体中的语境坍塌（context collapse）。语境坍塌指社交媒体用户在表达时往往面对分化的受众群体，群体间的差异被笼统的“联系人”标签掩盖。 很多研究关注到合法哀悼者的等级制（the hierarchy of legitimate mourners）这一现象。 对名人的线上哀悼：人们在线上哀悼与他们不相干的明星，而这种表达的背后依然有建立在线下社会关系上的“真情实感”。个人和群体认同在哀悼活动中被塑造，被哀悼的明星从来都不是主角，甚至悲痛这种情感也不是，哀悼者自己才是。 有研究者分析了线上哀悼者的叙事模式，指出线上哀悼实质是一种分享行为，这种分享让哀悼者可以得到来自他人的情感支持，让他们在群体中感受亲密感，同时又提供了免于与他人直接互动的空间，更好了满足了哀悼者的情感需求，最终达到更好的疗伤效果。 社交媒体中的哀悼还可能会建构一种集体的感知与记忆，这一点对于社会边缘群体尤其重要。 社会学家迈克尔·哈维德·雅各布森（Michael Hviid Jacobsen）则在此基础上指出，我们现在正在经历新的一轮转变，“壮观死亡”（spec-tacular death）的时代到来了。 当戈夫曼遇到互联网——社交媒体中的自我呈现与表演 欧文 · 戈夫曼出版了《日常生活中的自我呈现》一书，他在冥冥中回应着莎士比亚的名言，将缘起于乔治·米德等人的符号互动论纳入日常生活自我呈现的微观分析中，抽丝剥茧地梳理人们的披露与表演。自此，社会科学研究中出现了前台与后台、给予与流露、个人与剧班等一组组崭新的概念。 但是戈夫曼意义上的自我呈现更像是一种日常表演，而在社交媒体中，自我呈现更接近于一种“陈列”。从舞台表演（performance）变成一种自我的展览会（exhibition）。 技术可供性（affordance）：指的是技术为行为提供的可能性。从社交媒体的自我呈现角度来看，具体的可供性至少包括：其一，我们能够在社交媒体上陈列或展示我们的数字痕迹（imprint）。其二，因为技术的限定，社交媒体的自我呈现又往往是缺少具体语境的，有学者称其为“线索隐褪的环境”（Cue-reduced environ-ment），也有学者借助梅罗维茨的思想，为之命名为语境坍塌（con-text collapse）。 戈夫曼的拟剧理论：前台（front stage）与后台（back stage） 前台：个体表演中以一般的和固定的方式有规律地为观察者定义情境的那一部分，是个人在表演期间有意无意使用的、标准的表达性装备 后台：那些被竭力抑制、可能有损于它所要造成的印象的行动 我们对于前台和后台的操纵，便是所谓的“印象管理”（impression management） 在分享的过程中，人们满足了自己被重视、被认可、被崇拜的需要，甚至还会渐渐对自己产生了一种自带光环的幻觉，迷恋上这种“自我中心主义社交”。 观众隔离与观众想象：我们在社交媒体中，面对的不再是日常生活中那些清晰可辨的观众，而是一种想象的观众（Imaginedaudience）。 互联网的发展催生了一种新型品味表演形式——文本表演（textual performance）。在互联网上的品味表演行为中，人们会注重表达的连贯性（expressive coherence）、进行自我审查，并且格外关注品味表演的效果——恰如其分的品味表演能够加强团体认同（group identification）。 计算机中介的人际传播研究（computer-mediated interpersonal communication）新的视野和挑战： 对中国研究者而言，本土生长出的社交媒体，例如微信、豆瓣等，具有独特的文化特质和理论潜力，是我们可以进一步挖掘的研究田野。 绝大多数互联网自我呈现研究都依托于戈夫曼的拟剧理论，极少研究会考虑到中国传统文化对自我呈现的影响。 关注社交媒体中的集体表演（例如家庭微信群）。在《日常生活中的自我呈现》一书中，戈夫曼所重点论述和强调的是“剧班”概念，这一概念突出了个体表演者之间的合作和协调。 对自我呈现研究的批判之一，便是这种分析太过“微观”化，又经常会沦为生活片段的“描述性”讨论。而品味表演”研究恰恰可以将戈夫曼和布尔迪厄相连接，将微观的日常分析与阶层分析相连接，为传统的自我呈现研究赋予了更多的意识形态色彩和社会批判色彩。然而，这方面的研究文献屈指可数，近十年来国外专门的理论研究数量仅有个位数字，且绝大多数为计算机学科的研究成果。","link":"/2019/12/26/%E8%91%A3%E6%99%A8%E5%AE%87%E8%80%81%E5%B8%88%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"文本挖掘","slug":"文本挖掘","link":"/tags/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/"},{"name":"游戏设计","slug":"游戏设计","link":"/tags/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/"},{"name":"2019年秋季","slug":"2019年秋季","link":"/tags/2019%E5%B9%B4%E7%A7%8B%E5%AD%A3/"},{"name":"实习总结","slug":"实习总结","link":"/tags/%E5%AE%9E%E4%B9%A0%E6%80%BB%E7%BB%93/"},{"name":"数据科学","slug":"数据科学","link":"/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"},{"name":"游戏评论","slug":"游戏评论","link":"/tags/%E6%B8%B8%E6%88%8F%E8%AF%84%E8%AE%BA/"},{"name":"游戏研究","slug":"游戏研究","link":"/tags/%E6%B8%B8%E6%88%8F%E7%A0%94%E7%A9%B6/"},{"name":"用研技能点亮","slug":"用研技能点亮","link":"/tags/%E7%94%A8%E7%A0%94%E6%8A%80%E8%83%BD%E7%82%B9%E4%BA%AE/"},{"name":"文本分析","slug":"文本分析","link":"/tags/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/"},{"name":"标签分析","slug":"标签分析","link":"/tags/%E6%A0%87%E7%AD%BE%E5%88%86%E6%9E%90/"},{"name":"游戏数值","slug":"游戏数值","link":"/tags/%E6%B8%B8%E6%88%8F%E6%95%B0%E5%80%BC/"},{"name":"坑不能白踩系列","slug":"坑不能白踩系列","link":"/tags/%E5%9D%91%E4%B8%8D%E8%83%BD%E7%99%BD%E8%B8%A9%E7%B3%BB%E5%88%97/"},{"name":"社交媒体","slug":"社交媒体","link":"/tags/%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93/"}],"categories":[{"name":"实习の菜鸡乱啄","slug":"实习の菜鸡乱啄","link":"/categories/%E5%AE%9E%E4%B9%A0%E3%81%AE%E8%8F%9C%E9%B8%A1%E4%B9%B1%E5%95%84/"},{"name":"课程作业","slug":"课程作业","link":"/categories/%E8%AF%BE%E7%A8%8B%E4%BD%9C%E4%B8%9A/"},{"name":"多读书","slug":"多读书","link":"/categories/%E5%A4%9A%E8%AF%BB%E4%B9%A6/"},{"name":"复习笔记","slug":"复习笔记","link":"/categories/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"面试","slug":"面试","link":"/categories/%E9%9D%A2%E8%AF%95/"},{"name":"多看论文","slug":"多看论文","link":"/categories/%E5%A4%9A%E7%9C%8B%E8%AE%BA%E6%96%87/"}]}